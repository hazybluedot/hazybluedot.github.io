<!DOCTYPE html>
<html lang='en'>
  <head>
    <meta charset='utf-8'>
    <title>A Brand New nano Site -</title>
    <link href='/stylesheets/screen.css' media='screen,projection' rel='stylesheet' type='text/css'>
    <link href='/stylesheets/link_icons.css' media='screen,projection' rel='stylesheet' type='text/css'>
    <link href='/stylesheets/print.css' media='print' rel='stylesheet' type='text/css'>
    <link href='/stylesheets/solarized.css' media='screen' rel='stylesheet' type='text/css'>
    <!--[if lt IE 8]>
      <link href='/output/stylesheets/ie.css' media='screen, projection' rel='stylesheet' type='text/css'>
    <![endif]-->
    <meta content='nanoc 3.6.3' name='generator'>
  </head>
  <body class='bp two-col light'>
    <div id='container'>
      <div id='header'>
        #!/dkm
      </div>
      <div id='sidebar'>
        <h2>About</h2>
        <a href="/teaching/">Teaching Philosophy</a>
        <!--= link_to('Philosophy', teach.rep(:pdf))-->
        <h2>Recent Posts</h2>
        <ul><a href="/2013/05/making-space/">Making Space</a></ul>
        <ul><a href="/2013/04/as-scholars-are-wont-to-do-poetry-of-the-brachristochrone-problem/">As Scholars are Wont to do: Poetry of the brachristochrone problem</a></ul>
        <ul><a href="/2013/04/todo-make-ece2524-obsolete/">ToDo: Make ECE2524 Obsolete</a></ul>
        <h2>imported posts</h2>
        <ul><a href="/2013/05/new-site/">New Site, New Framework</a></ul>
        <ul><a href="/2013/05/open-source-treks-to-the-final-frontier/">And Now You're an Anstronaut: Open Source Treks to The Final Frontier</a></ul>
        <ul><a href="/2013/05/something-funny-about-school-part-1/">Something Funny about School (Part 1)</a></ul>
        <ul><a href="/2013/04/not-making-this-up-the-medium-is-the-message/">Not making this up: The Medium is the Message</a></ul>
        <ul><a href="/2013/04/nyquist-frequency-of-a-concept/">Nyquist frequency of a concept?</a></ul>
        <ul><a href="/2013/04/both-sides-of-auto-grading-argument-miss-the-point/">Both sides of auto-grading argument miss the point</a></ul>
        <ul><a href="/2013/04/cheating-by-the-rules/">Cheating by the Rules</a></ul>
        <ul><a href="/2013/04/how-will-we-build-a-third-system-of-education/">How will we build a Third System of education?</a></ul>
        <ul><a href="/2013/03/digital-amplifier-the-tweet-heard-round-the-world/">Digital amplifier: the tweet heard 'round the world</a></ul>
        <ul><a href="/2013/03/we-are-the-medium-directors-cut/">We are the medium? (director's cut)</a></ul>
        <ul><a href="/2013/03/about-time-idioms-about-time/">About Time: Idioms About Time</a></ul>
        <ul><a href="/2013/03/about-time/">About Time</a></ul>
        <ul><a href="/2013/03/humans-in-the-loop/">Humans in the loop</a></ul>
        <ul><a href="/2013/03/are-we-all-ice-skaters/">Are we all ice skaters?</a></ul>
        <ul><a href="/2013/03/are-we-sacrificing-creativity-for-content/">Are we sacrificing creativity for content?</a></ul>
        <ul><a href="/2013/03/ibreakit-ifixit/">iBreakit, iFixit</a></ul>
        <ul><a href="/2013/02/creative-writing-technically/">Creative writing, technically</a></ul>
        <ul><a href="/2013/02/i-am-a-selfish-git-a-bit-on-my-teaching-philosophy/">I am a Selfish Git: A bit on my teaching philosophy</a></ul>
        <ul><a href="/2013/02/a-comment-on-a-comment-on-commenting/">A Comment on "A comment on commenting"</a></ul>
        <ul><a href="/2013/02/blasphemy-drmed-games-on-linux/">Blasphemy?: DRMed Games on Linux</a></ul>
        <ul><a href="/2013/02/git-games-and-meta-moments/">Git Games and Meta Moments</a></ul>
        <ul><a href="/2013/02/does-awareness-of-our-limitations-aid-in-overcoming-them/">Does awareness of our limitations aid in overcoming them?</a></ul>
        <ul><a href="/2013/02/on-farming-the-internet-and-funny-hats/">On Farming, the Internet and Funny Hats</a></ul>
        <ul><a href="/2013/01/stranger-in-a-commonplace-land/">Stranger in a Commonplace Land</a></ul>
        <ul><a href="/2013/01/its-a-feature-not-a-bug/">It's a Feature, not a Bug</a></ul>
        <ul><a href="/2012/12/semester-in-review/">Semester in Review</a></ul>
        <ul><a href="/2012/12/211/">Re: the little things of ubuntu</a></ul>
        <ul><a href="/2012/12/structure-language-and-art/">Structure, Language and Art</a></ul>
        <ul><a href="/2012/12/the-tides-of-change/">The Tides of Change?</a></ul>
        <ul><a href="/2012/11/re-large-scale-makefiles/">Re: large scale makefiles</a></ul>
        <ul><a href="/2012/10/response-to-class-material-reposted/">Response to "Class Material – reposted"</a></ul>
        <ul><a href="/2012/10/list-of-projects-past/">List of Projects Past</a></ul>
        <ul><a href="/2012/10/response-to-advanced-python-exercises/">Response to "Advanced Python exercises"</a></ul>
        <ul><a href="/2012/09/but-what-does-it-all-mean/">But What Does It All Mean?</a></ul>
        <ul><a href="/2012/09/mary-poppins/">Mary Poppins</a></ul>
        <ul><a href="/2012/09/rule-of-diversity-distrust-all-claims-for-one-true-way/">Rule of Diversity: Distrust all claims for “one true way”.</a></ul>
        <ul><a href="/2012/08/what-makes-good-software-good/">What Makes Good Software Good?</a></ul>
        <ul><a href="/2012/05/it-may-be-satire/">It may be satire...</a></ul>
        <ul><a href="/2012/05/a-matter-of-standards/">A Matter of Standards</a></ul>
        <ul><a href="/2012/04/industrialized-learning-knowledge-information/">Industrialized Learning: Knowledge != Information</a></ul>
        <ul><a href="/2012/04/the-freedom-to-be-technologically-elite/">The Freedom to be "Technologically Elite"</a></ul>
        <ul><a href="/2012/03/strengthen-your-strength-know-your-weaknesses/">Strengthen your Strengths, know your Weaknesses</a></ul>
        <ul><a href="/2012/02/academic-privileged-experiences-as-a-white-cisgendered-gay-male-atheist-engineer/">Academic Privilege: Experiences as a white cisgendered gay male atheist Engineer</a></ul>
        <ul><a href="/2012/02/when-politics-attack/">When Politics Attack</a></ul>
        <ul><a href="/2012/02/blogging-is-hard/">Blogging is hard</a></ul>
        <h2>Recent Tweets</h2>
        <h2>Follow</h2>
        <a href='/feed.xml'>
          <img src='/assets/Feed-icon.svg.png'>
        </a>
      </div>
      <div id='content'>
        <div class='post'>
          <h1>
            <a href="/2013/05/new-site/">New Site, New Framework</a>
          </h1>
          <aside>Posted at: May 22, 2013</aside>
          <article>
            <h2 id="goodbye-wordpress">Goodbye Wordpress</h2>
            
            <p>For the past two years I have been using Virginia Tech’s
            <a href="https://blogs.lt.vt.edu/">Blogs@VT</a> service to host my blog. It’s
            been nice and all, but my goal had always been to move away from the
            VT hosted option and away from <a href="http://www.wordpress.org">WordPress</a>
            too.</p>
            
            <h2 id="hello-nanoc">Hello Nanoc</h2>
          </article>
        </div>
        <div class='post'>
          <h1>
            <a href="/2013/05/making-space/">Making Space</a>
          </h1>
          <aside>Posted at: May 15, 2013</aside>
          <article>
            <blockquote>
              <p>How to go about creating a space that facilitates learning? As we
            learned from Morningstar and Farmer, there is a danger of
            over-designing the space and often the users don’t end up using the
            space in the way the designer intended. So we shouldn’t
            over-design. But there should probably be some kind of structure,
            right? Or why create the space at all? <cite>- my brain</cite></p>
            </blockquote>
            
            <p>These are some of the thoughts that were going through my head as I
            set out to plan my final project. Throughout the semester a common
            focus of mine has been the lack of a space in my own field (Electrical
            &amp; Computer Engineering) to facilitate making connections between the
            work that goes on in the department, both teaching and research, and
            the outside world.</p>
            
            <div class='read-more'><a href='/2013/05/making-space/'>Continue reading &rsaquo;</a></div>
          </article>
        </div>
        <div class='post'>
          <h1>
            <a href="/2013/05/open-source-treks-to-the-final-frontier/">And Now You're an Anstronaut: Open Source Treks to The Final Frontier</a>
          </h1>
          <aside>Posted at: May 15, 2013</aside>
          <article>
            <p>There have <a href="http://blogs.lt.vt.edu/leonp/2013/05/08/here-comes-linux/">been</a> a <a href="https://blogs.lt.vt.edu/hussaino/2013/05/15/linux-dominating-space/">couple</a> of blog posts recently referencing the recent switch <a href="http://www.nasa.gov/">NASA</a> made from Windows to <a href="http://www.debian.org/">Debian 6</a>, a <a href="http://www.gnu.org/gnu/linux-and-gnu.html">GNU/Linux</a> distribution, as the OS running on the laptops abord the <a href="http://www.nasa.gov/mission_pages/station/main/index.html">International Space Station</a>. It’s worth noting that Linux is no stranger to the ISS, as it has been a part of ground control operations <a href="http://www.linux-magazine.com/w3/issue/12/Linux_on_the_International_Space_Station.pdf%20">since the beginning</a>.</p>
            
            <p>The reasons for the space-side switch <a href="http://www.zdnet.com/to-the-space-station-and-beyond-with-linux-7000014958/">are quoted</a> as</p>
            
            <blockquote>
              <p>…we needed an operating system that was stable and reliable – one that would give us in-house control. So if we needed to patch, adjust, or adapt, we could.</p>
            
              <p>This is satisfying to many Open Source/Linux fans in it’s own right: a collaborative open source project has <a href="http://en.wikipedia.org/wiki/Internet">once again</a> proved itself more stable and reliable for the (relatively) extrodinary conditions of low Earth orbit than a product produced by a major software giant. Plus one for open source collaboration and peer networks!</p>
            </blockquote>
            
            <p>But theres another reason to be excited. And it’s a reason that would not necessarily applied (<a href="https://www.youtube.com/watch?v=7XTHdcmjenI#t=9m08s">mostly</a>) to, say, Apple fanatics had NASA decided to switch to OS X instead of Debian. And that reason has to do with the collaborative nature of the open source movement, codified in many open source licenses under which the software is released. Linux, and the GNU tools, which together make up a fully functional operating system, are released under the <a href="http://www.gnu.org/copyleft/gpl.html">GNU General Public License</a>. Unlike many licenses used for commersial software, the GPL esures that software licenses under its terms remains free for users to use,modify and redistribute. There are certainly some strong criticisms and <a href="https://blogs.oracle.com/roumen/entry/sun_s_criticism_of_gpl">ongoing debate</a> regarding some key aspects of the GPL, especially <a href="http://www.osnews.com/story/19133/Torvalds_Still_Will_Not_License_Linux_Under_GPL_v3/">version 3</a>, the point of contention mostly lies in what is popularly called the “viral” effect of the license: that modified and derived work must also be released under the same license. The GPL might not be appropriate for every developer and every project, but it codifies the spirit of open source software in a way that is agreeable with many developers and users.</p>
            
            <p>So what does this all mean in terms of NASA’s move? We already know that they chose GNU/Linux for its reliability and stability over alternatives, but that doesn’t mean it’s completely bug free, or will always work perfectly with every piece of hardware, which after all is another reason for the switch: no OS will be completely bug free or always work with all hardware, but at least Debian gives NASA the flexibility of making improvements themselves. And there in lies the reason for excitement. While there is no requirement that NASA redistribute their own modified versions of the software, there is no reason to assume they wouldn’t in most cases, and if they do, it will be redistributed under the same license. It’s certainly realistic to expect they will be directing a lot of attention to making the Linux kernel, and the GNU tools packaged with Debian even more stable and more reliable, and those improvements will make their way back into the general distributions that we all use. This means better hardware support for all GNU/Linux users in the future!</p>
            
            <p>And of course it works both ways. Any bug fixes you make and redistribute may make their way back to the ISS, transforming humanity’s thirst for exploring “the final frontier” into a truly collaborative and global endeavor.</p>
          </article>
        </div>
        <div class='post'>
          <h1>
            <a href="/2013/05/something-funny-about-school-part-1/">Something Funny about School (Part 1)</a>
          </h1>
          <aside>Posted at: May 12, 2013</aside>
          <article>
            <p>In the last “adult” class of the semester the reading du jour was Scott McCloud’s “Time Frames”, a comic about comics. Specifically, how the passage of time, including motion, are depicted in the medium. The discussion that started as we talked about the gap in between frames of a comic got me thinking… [](https://blogs.lt.vt.edu/shebang/files/2013/05/panel1.png)[](https://blogs.lt.vt.edu/shebang/files/2013/05/panel2.png)[](https://blogs.lt.vt.edu/shebang/files/2013/05/panel3.png) Sometime in the not-so-distant past… [](https://blogs.lt.vt.edu/shebang/files/2013/05/heraclitus1.png)[](https://blogs.lt.vt.edu/shebang/files/2013/05/heraclitus2.png)[](https://blogs.lt.vt.edu/shebang/files/2013/05/heraclitus3.png)[](https://blogs.lt.vt.edu/shebang/files/2013/05/sea1.png)[](https://blogs.lt.vt.edu/shebang/files/2013/05/jack_and_rose.png)[](https://blogs.lt.vt.edu/shebang/files/2013/05/titanic1.png)[](https://blogs.lt.vt.edu/shebang/files/2013/05/iceburg1.png)[](https://blogs.lt.vt.edu/shebang/files/2013/05/iceburg2.png)[](https://blogs.lt.vt.edu/shebang/files/2013/05/brachristochrone1.png)[](https://blogs.lt.vt.edu/shebang/files/2013/05/brachristochrone2.png)[](http://blogs.lt.vt.edu/shebang/files/2013/05/chart1.png)[](http://blogs.lt.vt.edu/shebang/files/2013/05/chart2.png)</p>
          </article>
        </div>
        <div class='post'>
          <h1>
            <a href="/2013/04/not-making-this-up-the-medium-is-the-message/">Not making this up: The Medium is the Message</a>
          </h1>
          <aside>Posted at: April 29, 2013</aside>
          <article>
            <table>
              <tbody>
                <tr>
                  <td>I’ve been meaning to post something about the interesting interactions between the unix commands <a href="http://linux.die.net/man/6/fortune">fortune</a> and <a href="http://linux.die.net/man/1/cowsay">cowsay</a>. This is not that post. Long story short, fortune prints a random tidbit to the terminal and cowsay takes an input string and draws an ASCII art cow with a speech bubble containing the text you sent to the command. In addition, there are a number of different “cows” that can be drawn and so when pairing up random fortunes and random cows can be a parataxis gold mine. Here’s the command I have in my bash login script that does just that: [code light=”true”] fortune -s</td>
                  <td>cowsay -f $( find /usr/share/cows -name ‘*.cow’</td>
                  <td>shuf</td>
                  <td>head -n 1 ) [/code] More on that in the “real” post, but for now, I couldn’t pass this up which popped up when I opened a new terminal window just now: [code light=”true”] s _________________________________ / “The medium is the message.” – \ \ Marshall McLuhan / ——————————— \ \_______ v__v \ \ O ) (oo)</td>
                  <td> </td>
                  <td>—-w</td>
                  <td>(__)</td>
                  <td> </td>
                  <td> </td>
                  <td> </td>
                  <td>\/\ [/code] ponder that for a bit.</td>
                </tr>
              </tbody>
            </table>
          </article>
        </div>
        <div class='post'>
          <h1>
            <a href="/2013/04/as-scholars-are-wont-to-do-poetry-of-the-brachristochrone-problem/">As Scholars are Wont to do: Poetry of the brachristochrone problem</a>
          </h1>
          <aside>Posted at: April 25, 2013</aside>
          <article>
            <p>Time is an important dimension to consider when tracing the path of a
            media-represented concept. This is a theme that has stuck with me
            since reading Brenda Laurel’s “The Six Elements and Causal Relations
            Among Them” and coming across this brilliant bit of prose:</p>
            
            <blockquote>
              <p>As scholars are wont to do, I will blame the vagaries of
            translation, figurative language, and mutations introduced by
            centuries of interpretation for this apparent lapse and proceed to
            advocate my own view. <cite>- Brenda Laurel, “The Six Elements and
            Causal Relations Among Them”</cite></p>
            </blockquote>
            
            <p>Which, should be noted, already inspired
            <a href="http://blogs.lt.vt.edu/shebang/2013/03/20/we-are-the-medium-directors-cut/">a previous post</a>.</p>
            
            <p>The particular idea that Laurel was referring to was one first
            explored by Aristotle over 2000 years prior, and I was struck with the
            eerie feeling of being transported into a conversation spanning
            millennia as well as minds. Like Michelangelo chipping away at a block
            of marble to reveal the sculpture hidden within, poets and
            philosophers carve away at the layers of representation in an attempt
            to reveal the essence of a concept encased within.</p>
            
            <p>It occurred to me that the same process is occurring in the sciences
            as well, although usually the bricks of representation<sup id="fnref:david"><a href="#fn:david" class="footnote">1</a></sup>, are
            mathematical symbols rather than linguistic. In a moment of
            serendipity, while I was musing over the conversation of this
            morning’s class, I opened a book on Nonlinear Geometric Control Theory
            that, a few weeks back, I had checked out of the library on a whim. If
            the title means little to you, rest assure, it does me as well. This
            is not a topic I am too familiar with, but for a reason I can not
            fully explain, ever since I was introduced very briefly to
            <a href="http://en.wikipedia.org/wiki/Differential_form">differential forms</a>
            in a <a href="http://en.wikipedia.org/wiki/Real_analysis">real analysis</a> class
            I suspected that the language of <a href="http://en.wikipedia.org/wiki/Differential_geometry">differential
            geometry</a> had the
            potential for elegant representations of optimal control problems. Low
            and behold, I opened this book and immediately saw a paper in which
            the authors, Sussmann and Willems, explored several representations of
            the <a href="http://www-history.mcs.st-and.ac.uk/HistTopics/Brachistochrone.html">brachistochrone
            problem</a>,
            concluding with a differential-geometric approach that they claimed as
            the most elegant thus far.</p>
            
            <h3 id="the-brachristochrone-problem">The brachristochrone problem</h3>
            
            <p>In 1696,
            <a href="http://en.wikipedia.org/wiki/Johann_Bernoulli">Johann Bernoulli</a>
            asked a question that has become a classical problem used as
            motivating example for
            <a href="http://en.wikipedia.org/wiki/Calculus_of_variations">calculus of variations</a>
            and rears its head again in
            <a href="http://en.wikipedia.org/wiki/Optimal_control">optimal</a> control<sup id="fnref:lcp"><a href="#fn:lcp" class="footnote">2</a></sup>:</p>
            
            <blockquote>
              <p>Given two points A and B in a vertical plane, what is the curve
            traced out by a point acted on only by gravity, which starts at A
            and reaches B in the shortest time. <cite>-
            <a href="http://www-history.mcs.st-and.ac.uk/HistTopics/Brachistochrone.html">The bracristochrone problem</a></cite></p>
            </blockquote>
            
            <p><img src="/assets/posts/Brachistochrone.png" alt="Brachistochrone problem"></p>
            
            <p>The problem itself is older than Bernoulli: Galileo had conducted his
            own exploration in 1638 and incorrectly deduce the solution to be the
            arc of a circle<sup id="fnref:brachristochrone"><a href="#fn:brachristochrone" class="footnote">3</a></sup>. Bernoulli’s revitalization of the
            question is what led to the first correct answer, that the solution is
            a <a href="http://en.wikipedia.org/wiki/Cycloid">cycloid</a></p>
            
            <p>Sussmann and Willems summarize the various solutions to the problem as
            follows:</p>
            
            <blockquote>
              <ol>
                <li>Johann Bernoulli’s own solution based on an analogy with
            geometrical optics,</li>
                <li>the solution based on the classical
            calculus of variations,</li>
                <li>the optimal control method, and, finally,  </li>
                <li>the differential-geometric approach</li>
              </ol>
            
              <p><cite>- Sussmann &amp; Willems</cite></p>
            </blockquote>
            
            <p>[place holder for a more in-depth summary…ran out of time tonight] </p>
            
            <p>They demonstrate how each successive method refines the solution space
            and eliminates unnecessary assumptions to approach what could be
            considered the essence of the problem itself. They end with the
            differential-geometric approach with the claim that it is thus far the
            best at elegantly capturing the problem, but it hardly seems like this
            will be the final word on such a well traveled challenge.</p>
            
            <p>So it seems the path the poet takes in exploring the nature of life is
            not all that dissimilar from the path the mathematician, scientist or
            engineer takes, only the tools differ, and even then, the difference
            is often over stated. They are all just different colors of bricks.</p>
            
            <h3 id="footnotes-and-references">Footnotes and References</h3>
            
            <div class="footnotes">
              <ol>
                <li id="fn:david">
                  <p>David, write about your brick analogy so I have something to link to!<a href="#fnref:david" class="reversefootnote">↩</a></p>
                </li>
                <li id="fn:lcp">
                  <p>worthy of an entirely separate post: through my digging around for more details about the <a href="http://www-history.mcs.st-and.ac.uk/HistTopics/Brachistochrone.html">brachistochrone problem</a> I discovered <a href="http://www.math.umt.edu/tmme/vol5no2and3/TMME_vol5nos2and3_a1_pp.169_184.pdf">a paper</a> discussing it as a Large Context Problem, an approach to education that is of extreme interest to me that I now have a name for!<a href="#fnref:lcp" class="reversefootnote">↩</a></p>
                </li>
                <li id="fn:brachristochrone">
                  <p><a href="http://www-history.mcs.st-and.ac.uk/HistTopics/Brachistochrone.html">The brachristochrone problem</a><a href="#fnref:brachristochrone" class="reversefootnote">↩</a></p>
                </li>
              </ol>
            </div>
          </article>
        </div>
        <div class='post'>
          <h1>
            <a href="/2013/04/nyquist-frequency-of-a-concept/">Nyquist frequency of a concept?</a>
          </h1>
          <aside>Posted at: April 21, 2013</aside>
          <article>
            <blockquote>
            
            </blockquote>
            
            <p>This past week in ECE3704 (Continuous and Discrete Systems) we have been exploring what happens to the information in a continuous-time signal when it is sampled and again what happens when discrete samples are reconstructed into a continuous time signal. Here is an example:</p>
            
            <p>[](https://blogs.lt.vt.edu/shebang/files/2013/04/signal.png)</p>
            
            <p>The solid blue line is the continuous time signal (x(t)=e^-t) and the black dots are samples of the signal taken at intervals of 0.5 seconds (the sampling period). This process of sampling a signal is a necessity of living in a (mostly) continuous-time world when processing data using a (theoretically) discrete-time device such as a digital computer. Once we have our information nicely digitized we can poke, prod and manipulate it using the wealth of digital tools at our disposal before converting it back to a continuous-time representation that we then observe, commonly in the form of visual or audible signals. The question arises: what does the act of sampling and reconstruction have on the final output that we see and hear? How faithful is the input/output relationship of our original and constructed signal using our digital technology to the ideal relationship. An illustrative example would be the combination of wireless and wired networks that make up the communication channel used to transmit the data associated with a cell phone call. Ideally, the receiver would hear an exact transcript of the audible information as produced by the caller, or at least as exact as it would have been if the two were face to face. In reality the best we can usually hope for is an approximate reconstruction that is “good enough”. Here is the reconstruction of our previously sampled signal, overlaid on the original for comparison.</p>
            
            <p>[](https://blogs.lt.vt.edu/shebang/files/2013/04/signal_con.png)</p>
            
            <p>Clearly the reconstructed signal is not a faithful duplicate of the original, but why is this the case, and what could we do to make it better? We gain some insight by taking a <a href="http://en.wikipedia.org/wiki/Fourier_transform">Fourier transform</a> of the sampled signal to generate a frequency spectrum which we can then compare with the frequency spectrum of the original.</p>
            
            <p>[](https://blogs.lt.vt.edu/shebang/files/2013/04/magX.png)</p>
            
            <p>The ability to view the signal from this vantage point makes some features of the sampling process easy to see that otherwise would not be obvious looking at the time-domain representation, namely, we note that the frequency spectrum of the continuous time signal can potentially live on the entire infinite frequency axis,</p>
            
            <p>[](https://blogs.lt.vt.edu/shebang/files/2013/04/magXstar.png)</p>
            
            <p>while the sampled signal is restricted to a finite frequency interval, the interval between plus and minus and half the sampling frequency, between the dashed red lines (it turns out that the frequency spectrum of all real-valued signals has a <a href="http://en.wikipedia.org/wiki/Negative_frequency">negative component</a> that mirrors the positive spectrum. Who knew?).</p>
            
            <p>The dashed red lines are drawn at plus and minus 2<em>pi radians/sec, the information starts repeating after this, shown by the green curve. Note that 2</em>pi rad/sec is one half the sampling frequency of 4*pi rad/sec. Viewing the information in this form allows us to intuit why we might not be able to uniquely reconstruct all sampled signals perfectly: The act of sampling is restricting the domain on which we can encode information to a finite interval, so we can conclude that sampled versions of continuous-time signals that make use of the entire infinite frequency axis will never contain all the information of the original signal, and for those signals that are naturally <a href="https://en.wikipedia.org/wiki/Bandlimiting">bandlimited</a> we will need to choose our sampling frequency in such a way that finite frequency interval of the discrete-time signal is large enough to contain all the information in the original. This leads to the <a href="https://en.wikipedia.org/wiki/Nyquist_sampling">Nyquist sampling theorem</a> which states that if the sampling frequency is greater than twice the bandlimit of the original signal then the signal can be uniquely reconstructed from its samples.</p>
            
            <p>In <a href="https://blogs.lt.vt.edu/oddwallaby/2013/04/17/medium/">a recent post</a>, <a href="https://blogs.lt.vt.edu/oddwallaby/author/aburke3/">Adam</a> commented that we (humans, though this most likely applies to any non-humans able to read and comprehend this just as well) engage in a sampling and reconstruction process every time we communicate a thought. Concepts and ideas live in the continuous domain (at least, so it seams, not being an expert in neuroscience perhaps one could make a sound argument that thoughts are in fact discrete, but for today’s purposes I think it would not be egregiously inaccurate to compare them to continuous-time signals), and yet there are only so many words we have available to us when communicating those thoughts. What’s more, we can’t be sure that another sentient being will hear the words we are using and reconstruct our original thought perfectly. In fact, it’s likely that this imperfect reconstruction of communicated thought results in a great deal of innovation and creativity and “thinking outside the box”, so it’s certainly not always a bad thing, just a thing. But it’s a thing we don’t really have any tools to quantitatively analyze. How much off the original information was lost or distorted by the conversion into language or another medium? How far from the original thought is the reconstructed thought (assuming we can even define a <a href="http://en.wikipedia.org/wiki/Metric_space#Definition">metric space</a> for concepts).</p>
            
            <p>It would seem that some thoughts, like signals, have bandlimited information content, while others may not. The feeling expressed by the phrase “I am thirsty” is fairly well understood (even if we don’t really understand what the essence of “I” is). There are some variations: “I am very thirsty”, “I am parched”, etc. but I’m going to go out on a limb and say that that particular thought can be accurately communicated in a finite number of words (generally about 3). I’m not sure I could make that claim about some others, like the concept of “I”. Are there more parallels between sampling theory and communication through a medium? It would seem that like signals, some ideas can be sampled and reconstructed accurately, while others can not. Are there any tools available that parallel <a href="https://en.wikipedia.org/wiki/Fourier_analysis">Fourier analysis</a> for signals that could yield a different view of the information contained in a raw idea or concept? Does it even make sense to talk about such a tool?</p>
          </article>
        </div>
        <div class='post'>
          <h1>
            <a href="/2013/04/todo-make-ece2524-obsolete/">ToDo: Make ECE2524 Obsolete</a>
          </h1>
          <aside>Posted at: April 9, 2013</aside>
          <article>
            <p>Why would I want to eliminate the course that I’ve been teaching the
            past four semesters, that I have put so many hours into to update
            content, create new assignments, written (and re-written each
            semester… another topic altogether) a set of scripts to facilitate
            reviewing stacks of programming assignments and generally had a great
            time with?</p>
            
            <p>Well, because I don’t think it should be a separate course to begin
            with. As many have noted, and I have agreed, ECE2524 in many respects
            is a kind of a “catch-all” course for all those really important
            topics and tools (version control, anyone?) that just don’t get
            covered anywhere else. It is also officially (but not rigorously
            enforced in the form of a prereq) to be an introduction to more
            advanced software engineering courses, so it has the general feel of a
            programming course.</p>
            
            <p>I think programming (and *nix OS usage and philosophy) is too
            important to delegate off to a 2 credit course and treat separately
            from the rest of the engineering curriculum, an idea that was
            solidified after reading an excerpt from Mindstorms by Seymour Papert.</p>
            
            <blockquote>
              <p>I began to see how children who had learned to program computers
            could use very concrete computer models to think about thinking and
            to learn about learning and in doing so, enhance their powers as
            psychologists and as epistemologists.</p>
            </blockquote>
            
            <p>Papert is a strong advocate to introducing computer programming to
            children at an early age and using it as a tool to learn other
            disciplines</p>
            
            <blockquote>
              <p>The metaphor of computer as mathematics-speaking entity puts the
            learner in a qualitatively new kind of relationship to an important
            domain of knowledge. Even the best of educational television is
            limited to offering quantitative improvements in the kinds of
            learning that existed without it… By contrast, when a child learns to
            program, the process of learning is transformed. It becomes more
            active and self-directed. In particular, the knowledge is acquired
            for a recognizable personal purpose.</p>
            </blockquote>
            
            <p>It goes without saying that a solid understanding of math is crucial
            for any of the STEM fields, but computers and programming can also
            encourage engagement with
            <a href="http://blogs.kqed.org/mindshift/2013/04/combining-robotics-with-poetry-art-and-engineering-can-co-exist/">other fields as well</a>,
            though that is not the focus of this post.</p>
            
            <p>Along with being a useful skill to have, programming teaches a
            systematic way of thinking about a problem, and crucially shifts the
            model of learning from one that embodies a “got it” and “got it wrong”
            binary state to one that encourages the question “how do I fix
            it?”. As Papert notes, and I can personally attest, when writing a
            program you never get it right the first time. Becoming a good
            programmer means becoming an expert at tracking down and fixing bugs.</p>
            
            <blockquote>
              <p>If this way of looking at intellectual products were generalized to
            how the larger culture thinks about knowledge and its acquisition,
            we all might be less intimidated by our fears of “being wrong.”</p>
            </blockquote>
            
            <p>Some strong arguments for the symbiosis of programming and learning
            valuable thinking skills at an early age. But the benefits don’t
            disappear at the college level, especially in a field such as
            engineering in which learning programming for the sake of programming
            is a valuable skill (there are several required classes on the
            subject, so you know it must be important. Slight sarcasm, but it’s
            true, regardless of how cynical we agree to be about the way classes
            are structured and the curriculum is built for us). If programming can
            help engage with learning mathematics, and as a side effect get us
            thinking about how we think, and shift our view of learning to a more
            constructive one, then can’t we get at least the same positive affects
            if we apply it to more advanced concepts and ideas? It doesn’t hurt
            that a good chunk of engineering is mathematics anyway.</p>
            
            <p>The wheels really started turning after the first day of
            guest-lecturing for Signals &amp; Systems. Here’s a course that is a lot
            of math, but critically foundational for learning how to learn about
            how the world works. That may seem a little embellished, especially
            for those not familiar with the field (Signals &amp; Systems crash course:
            a system is anything that has an input signal and produces and output
            signal, e.g. a car (input is gas/break, output is speed), a heart beat
            (input is electrical signal transmitted along nerves, output is muscle
            contraction or blood flow), the planet (so many systems, but treating
            atmospheric concentrations of CO2 and other gases as an input and the
            average global temperature would be one example of a system we would
            be interested in studying)). Signals &amp; Systems provides a set of tools
            for exploring the input/output relationships of… anything.</p>
            
            <p>So why is it taught from a set of slides?</p>
            
            <p>What better way to really engage with and understand the theory than
            USE it? Now most educational budgets wouldn’t be able to cover the
            costs if everyone wanted to learn the input/output behavior of their
            own personal communications satellite, but the beauty of Signals &amp;
            Systems, and the mathematical representations that it embodies, is
            that everything can be simulated on a computer. From the velocity of a
            car, to blood flow caused by a beating heart, to the motion of the
            planets and beyond.</p>
            
            <p>I envision a Signals &amp; Systems course that is mostly
            programming. People will argue that the programming aspect of the
            material is just the “practical implementation”, and while that’s
            important, the theory is critical. Yes, the theory is what helps us
            develop a generalized insight into different ways of representing
            different types of systems and what allows us to do a good deal of
            design in a simulated environment with greatly reduced risks,
            especially when say, designing new flight controls for a commercial
            jet.</p>
            
            <p>But I think the theory can be taught alongside the programming for a
            much richer experience than is obtained by following a set of
            slides. You want to understand how the
            <a href="http://en.wikipedia.org/wiki/Laplace_transform">Laplace transform</a>
            works? What better way than to implement it on a computer. I guarantee
            you, if you have to write a program that calculates the Laplace
            transform for an arbitrary input signal, by the time you’re done with
            the debugging, you’re going to have a pretty good understanding of
            whats going on, not to mention a slew of other important experiences
            (how do you solve an integral on a computer anyway?).</p>
            
            <p>Talking about the differences between continuous time systems and
            discrete time systems is taken to a whole new level when you start
            trying to simulate a continues-time system on a computer, very much a
            discrete-time system. How do you even do that? Is it sufficient to
            just use a really really small time step?</p>
            
            <p>So yes, I think the best case scenario would be one in which ECE2524:
            Intro to Unix for Engineers is obsolete<sup id="fnref:focus"><a href="#fn:focus" class="footnote">1</a></sup>. Not because the topics we
            cover are unimportant, quite the contrary, they are so important that
            they should be providing a framework for learning engineering.</p>
            
            <h2 id="footnotes">Footnotes:</h2>
            
            <div class="footnotes">
              <ol>
                <li id="fn:focus">
                  <p>I’ve focused primarily on the programming aspect of ECE2524
            here, but those of you who know me and have taken the course with
            me know that the Unix philosophy is a big part of it as
            well. Integrating the programming aspects into other coursework
            would of course not address that. I’m sure, with a little thought
            we all can think up a clever way of introducing the *nix
            philosophy and generally the whole concept of thinking about a
            philosophy when thinking about engineering, and what that even
            means, with every other course. Because well, it should be an
            integral part of everything else we learn.<a href="#fnref:focus" class="reversefootnote">↩</a></p>
                </li>
              </ol>
            </div>
          </article>
        </div>
        <div class='post'>
          <h1>
            <a href="/2013/04/both-sides-of-auto-grading-argument-miss-the-point/">Both sides of auto-grading argument miss the point</a>
          </h1>
          <aside>Posted at: April 4, 2013</aside>
          <article>
            <p><a href="http://www.nytimes.com/2013/04/05/science/new-test-for-computers-grading-essays-at-college-level.html?pagewanted=1&amp;_r=0&amp;smid=fb-share">A recent story</a> in the New York Times covers a software program by nonprofit EdX that will soon be available for free to any institution that wants to use it. Using sophisticated machine learning algorithms to train its artificial intelligence, the software will grade essays and short response questions and provide nearly instant feedback. Naturally there are strong supporters for the new software touting it for “freeing professors for other tasks” (like what?). And just as naturally there are <a href="http://graphics8.nytimes.com/packages/pdf/science/Critique_of_Shermis.pdf">strong critics</a> who have formed a group called <a href="http://humanreaders.org/petition/">Professors Against Machine Scoring Essays in High-Stakes Assessment</a>. From the group’s petition:</p>
            
            <blockquote>
              <p>Let’s face the realities of automatic essay scoring. Computers cannot “read.” They cannot measure the essentials of effective written communication: accuracy, reasoning, adequacy of evidence, good sense, ethical stance, convincing argument, meaningful organization, clarity, and veracity, among others.</p>
            
              <p>While criticism is certainly warranted, I find the quote to be somewhat bullish. Can these people really claim that they understand how they are able to read and measure the essentials of effective written communication well enough that they can look at a computer and say with confidence, “that can not do what I am doing, and here’s why”? It very well may be that current AI programs do not have the ability to comprehend written communication to a degree necessary to assign grades, but to make the argument that the software shouldn’t be used because “computers cannot ‘read’”, as if that were a self-evident fact is just poor communication.</p>
            </blockquote>
            
            <p>Now to be fair, I disagree with the supporters of the software as well.</p>
            
            <blockquote>
              <p>“There is a huge value in learning with instant feedback,” Dr. Agarwal said. “Students are telling us they learn much better with instant feedback.”</p>
            
              <p>Ok, well, not that part, I agree with that part in principle. But what kind of feedback? Supposedly the software can generate a grade and also comments whether or not the essay was “on topic”. So a student could get instant feedback, which is great, and then edit and modify, which is great, and resubmit, which is also great… and then what? What would they be learning?</p>
            </blockquote>
            
            <p>I promise to be highly skeptical of any answer to that question that isn’t “how to write an essay that receives high marks from an automatic grading AI”.</p>
            
            <p>All this talk about feedback. What about feedback for the professor? I find reading through 60 essays just as tedious and time consuming as the next out-of-place grad student in a department that doesn’t value teaching, but I also recognize that reading those essays is a valuable way for me to gauge how I’m doing. Are the concepts that I think are important showing up? Are there any major communication issues? What about individuals, are some struggling, what can I do to help? How will I learn my students’ personalities and how that might affect their personal engagement with the material? How will I learn to be a better educator?</p>
            
            <p>Granted, even though 60 feels overwhelming, it’s nowhere near 200 or more. I can’t even imagine trying to read through that many assignments myself. I’m confident that if I were force to I would not emerge with my sanity intact. This problem does not go unaddressed.</p>
            
            <blockquote>
              <p>With increasingly large classes, it is impossible for most teachers to give students meaningful feedback on writing assignments, he said. Plus, he noted, critics of the technology have tended to come from the nation’s best universities, where the level of pedagogy is much better than at most schools.</p>
            
              <p>“Often they come from very prestigious institutions where, in fact, they do a much better job of providing feedback than a machine ever could,” Dr. Shermis said. “There seems to be a lack of appreciation of what is actually going on in the real world.”</p>
            
              <p>An “A” for recognizing the problem. But the proposed solution is nothing more than a patch. In fact, it’s worse, because it is a tool that will enable the continual ballooning of class size. And to what expense? Why don’t you rethink your solution and have it on my desk in the morning. I can’t promise instant feedback, but maybe, just maybe, the feedback provided will be the start to moving in a direction that actually addresses the underlying problems, rather than just using technology to hide them.</p>
            </blockquote>
          </article>
        </div>
        <div class='post'>
          <h1>
            <a href="/2013/04/cheating-by-the-rules/">Cheating by the Rules</a>
          </h1>
          <aside>Posted at: April 3, 2013</aside>
          <article>
            <h3 id="is-it-still-cheating-if-the-rules-are-made-up">Is it still cheating if the rules are made up?</h3>
            
            <blockquote>
              <p>Successful and fortunate crime is called virtue.</p>
            
              <ul>
                <li>Seneca</li>
              </ul>
            
              <p>During our discussion about <a href="http://www.youtube.com/watch?v=VVpulhO3jyc">Lucasfilm’s Habitat</a> earlier in the week we talked a lot about how the lessons learned by the designers for effectively building a virtual world mirrored a lot of what we knew about building a virtual world in the real world.</p>
            </blockquote>
            
            <p>Woah, what? Don’t I mean mirrored by our real actions in the real world? Or the real things we have built in the real world?</p>
            
            <p>Not really, the more I thought about it, the more I notice similarities between the virtual environment that Morningstar and Farmer built and our own world, commonly called “the real world”.</p>
            
            <h3 id="keeping-reality-consistent">Keeping “Reality” Consistent</h3>
            
            <p>As we have discussed before in class, it seems that most people understand on some level that their own core values differ, sometimes significantly, from what our society visibly places value on. We talked about what it means to truly experience life and many of us painted images of being in nature and absorbing all the sights, sounds, and sensations that were available. We know what we need to sustain life (sufficient food and shelter) and we know what we need to be happy (close, meaningful relationships with those around us). And yet look at the world we have created for ourselves. Today, we essentially live in what Morningstar and Farmer called an “experiential level”, this is the level in which the rules that we follow are the rules that were constructed to facilitate the illusion. It is somewhat removed from the “infrastructure level”, and it seems as time goes on, there is less and less “leakage” between the two levels. Morningstar and Farmer would be proud.</p>
            
            <p>To be fair, they were writing in the context of a game designed for the purposes of allowing a player to (temporarily) allow themselves to be overcome by the illusion for entertainment. If that’s the goal, then yes, a leak-free relationship between the “infrastructure level” and the “experiential level” would seem necessary. But have we inadvertently set up the same type of structure in our “real” world?</p>
            
            <p>It is both interesting and suggestive that we often use the same word to describe the rules we use to govern ourselves as the rules we have deduced govern the universe. The laws of physics are not ones that often are showcased in our courts of law, and yet the concept of a “law” seems to be somehow applicable to both. Is it surprising then that we often think a particular action is impossible because “it’s against the law”</p>
            
            <p>There was a time when many protested that humans were not meant to fly, for it went against the laws of nature. Gravity, and a dense body structure, kept us firmly rooted on the ground, who were we to argue with the laws of nature? And yet, we figured out a way to cheat.</p>
            
            <p>But it’s not really cheating if we’re playing by the rules. We just learned the rules well enough to discover a loophole. Of course, I am somewhat intentionally misconstruing the situation. The “law” of gravity never said “humans may not fly” (and for now let’s ignore the pesky question of whether or not we are flying, or our machines are and we’re just along for the ride). The point is, we are continuously refining our understanding of the “laws” of nature, but the laws themselves, the underlying equations that govern the universe, are not themselves being modified with our increased understanding.</p>
            
            <p>Our own laws and abstractions are of course much more mutable, but it makes sense that we wouldn’t treat them as such. After all, laws would quickly loose their meaning if we were re-writing them willy-nilly. But I wonder if sometimes we are so immersed in our own virtual reality that we forget that it is virtual.</p>
            
            <p>The resent series of financial “crisis” comes to mind. During the whole debacle, every time someone talked about the impending doom that would be upon us if we didn’t act (or if we did, or if we acted incorrectly…) I wanted to shake them and say, “you do know we’re making this all up, don’t you?”</p>
            
            <p>It’s interesting that people will express surprise, skepticism, or disbelief when they encounter a gamer who has exchanged virtual goods for real world money to purchase and consume actual physical food. “People actually will pay you for something that’s not even real?”</p>
            
            <p>Why are they so shocked? People on Wall Street have known this for decades.</p>
            
            <p>[](http://xkcd.com/1173/)</p>
          </article>
        </div>
        <div class='post'>
          <h1>
            <a href="/2013/04/how-will-we-build-a-third-system-of-education/">How will we build a Third System of education?</a>
          </h1>
          <aside>Posted at: April 1, 2013</aside>
          <article>
            <p>I have recently been reading about, as Mike Gancarz puts it in Linux and the Unix Philosophy, “The Three Systems of Man”. This is, to my understanding, a fairly well documented and often-observed concept in software design, possibly first referenced by Frederick Brooks in The Mythical Man-Month when he coined “<a href="http://en.wikipedia.org/wiki/Second-system_effect">the second system effect</a>”. Gancarz seems to take the concept further, generalizing it to any system built by humans.</p>
            
            <blockquote>
              <p>Man has the capacity to build only three systems. No mater how hard he may try, no matter how many hours, months, or years for which he may struggle, he eventually realizes that he is incapable of anything more. He simply cannot build a fourth. To believe otherwise is self-delusion.</p>
            
            </blockquote>
            
            <h3 id="the-first-system">The First System</h3>
            
            <p>Fueled by need, constricted by deadlines, a first system is born out of a creative spark. It’s quick, often dirty, but gets the job done well. Importantly it inspires others with the possibilities it opens up. The “what if”s elicited by a First System lead to…</p>
            
            <h3 id="the-second-system">The Second System</h3>
            
            <p>Encouraged and inspired by the success of the First System more people want to get on bored and offer their own contributions and add features they deem necessary. Committees are formed to organize and delegate. Everyone offers their expertise and everyone believes they have expertise, even when they don’t. The Second System has a marketing team devoted to selling its many features to eagerly awaiting customers, and to appeal to the widest possible customer base nearly any feature that is thought up is added. In reality, most users end up only using a small fraction of available features of The Second System, the rest just get in the way. Despite enjoying commercial success The Second System is usually the worse of the three. By trying to appease everyone (and more often then not, by not understanding , the committees in charge have created a mediocre experience. The unnecessary features add so much complexity that bugs are many and fixes take a considerable amount of effort. After some time, some users (and developers) start to recognize The Second System for what it is: bloatware.</p>
            
            <h3 id="the-third-system">The Third System</h3>
            
            <blockquote>
              <p>The Third System is built by people who have been burned by the Second System</p>
            
              <p>Eventually enough people grow frustrated by the inefficiencies and bloat of The Second System that they rebel against it. They set out to create a new system that contains the essential features and lessons learned in the First and Second Systems, but leave out the crud that accumulated by the Second System. The construction of a Third System comes about either as a result of observed need, or as an act of rebellion against the Second System. Third Systems challenge the status quo set by Second Systems, and as such there is a natural tendency to those invested in The Second System to criticize, distrust and fear The Third System and those who advocate for it.</p>
            </blockquote>
            
            <h3 id="the-interesting-history-of-unix">The Interesting History of Unix</h3>
            
            <p>Progression from First to Second to Third system always happens in that order, but sometimes a Third System can reset back to First, as is the case with Unix. While Gancarz argues that current commercial Unix is a Second System, the original Unix created by a handful of people at Bell Labs <a href="http://www.faqs.org/docs/artu/ch02s01.html">was a Third System</a>. It grew out of the Multics project which was the Second System solution spun from the excitement of the Compatible Time-Sharing System (CTSS), arguably the first timesharing system ever deployed. Multics suffered so much from second-system syndrome that it collapsed under its own weight.</p>
            
            <p>Linux is both a Third and Second system: while it shares many properties of commercial Unix that are Second System-like, it is under active development by people who came aboard as rebels of Unix and who put every effort into eliminating the Second System cruft associated with its commercial cousin.</p>
            
            <h3 id="is-our-current-educational-complex-a-second-system">Is our current Educational Complex a Second System?</h3>
            
            <p>I see many signs of second-system effect in our current educational system. Designed and controlled by committee, constructed to meed the needs of a large audience while failing to meet the individual needs of many (most?). Solutions to visible problems are also determined by committee and patches to solutions serve to cover up symptoms. Addressing the underlying causes would require asking some very difficult questions about the nature of the system itself. Something that those invested in it are not rushing to do.</p>
            
            <h3 id="building-a-third-system">Building a Third System</h3>
            
            <p>What would a Linux-esq approach to education look like? What are the bits that we would like to keep? What are the ugliest pieces that should be discarded first? And how will we weave it all together into a functional, useful system?</p>
          </article>
        </div>
        <div class='post'>
          <h1>
            <a href="/2013/03/digital-amplifier-the-tweet-heard-round-the-world/">Digital amplifier: the tweet heard 'round the world</a>
          </h1>
          <aside>Posted at: March 26, 2013</aside>
          <article>
            <p>Sometimes, in the face based modern world we live in, it feels like we’re living in the future. But all it takes is the watchful eye of the Internet, and specifically, its uncanny, sometimes disruptive tendency to amplify lurking social ills to remind us we are still very much in the past.</p>
            
            <p>Last week, <a href="https://us.pycon.org/2013/">PyCon</a> nearly ended quietly, without causing much of ruckus, as all good annual gatherings of open source software developers strive for. The organizers of PyCon understand the importance of diversity in the technology field, a currently white male dominated field, have worked hard to create an environment that is open and welcome to everyone, and in case there’s any confusion, they have a published <a href="https://us.pycon.org/2013/about/code-of-conduct/">code of conduct</a>.</p>
            
            <p>So when Adria Richards grew frustrated with two men making lewd jokes behind her at a closing talk she snapped their picture and tweeted</p>
            
            <blockquote>
              <p>Not cool.Jokes about forking repo’s in a sexual way and “big” dongles.Right behind me <a href="https://twitter.com/search/%23pycon">#pycon</a><a href="http://t.co/Hv1bkeOsYP">twitter.com/adriarichards/…</a></p>
            
              <p>— Adria Richards (@adriarichards) <a href="https://twitter.com/adriarichards/status/313417655879102464">March 17, 2013</a>
             Moments later, PyCon staff saw her tweet, responded and escorted the two men into the hallway. The situation was resolved with minimal disruption. It would have all been finished, and we wouldn’t be still talking about it now if it hadn’t been for the first inappropriate response to the, up until this point, fairly minor ordeal.</p>
            </blockquote>
            
            <p>The company for which the two men were working for, and representing at PyCon, made the decision to fire one of them. The company sited multiple contributing factors, not just the joke, but the timing was extreamly poor on their part if they really didn’t want to connect the termination to the joke incident.</p>
            
            <p>And then the Internet exploded.</p>
            
            <p>Adria Richards got a man fired. A man who had three children to feed. The Internet was not pleased. And to show its displeasure it sent Adria death threats, rape threats, racial epithets and suggested that she consider suicide. A group of hackers, some claiming to be Anonymous, initiated a <a href="http://venturebeat.com/2013/03/21/sendgrid-under-ddos-attack-after-its-developer-evangelist-complains-about-sexual-jokes-at-pycon/">series of DDOS attacks</a> on her employer’s servers demanding that they fire her for retribution.</p>
            
            <p>And because SendGrid, the company employing Adria, had no spine, they gave into the mob and publicly fired her. It was the easy thing to do, after all.</p>
            
            <p>Justice served?</p>
            
            <p>Bloggers the tech world over chimed in with their support or critique. Many asking whether <a href="http://www.forbes.com/sites/quora/2013/03/22/was-it-appropriate-for-adria-richards-to-tweet-a-photo-of-two-men-at-pycon-and-accuse-them-of-being-sexist/">she should have posted the photo</a> of the two men and how she should have handled the incident differently, in a more lady-like fashion. Many jumped on <a href="http://amandablumwords.wordpress.com/2013/03/21/3/">a post by Amanda Blum</a> that proved Richards “acted out” like this on more than one occasion, though Blum mentioned that she does not like Adria personally, and criticized her actions at PyCon, she did bring up the point that</p>
            
            <blockquote>
              <p>Within 24 hours, Adria was being attacked with the vile words people use only when attacking women.</p>
            
              <p>And this is the real issue, I think. And the bashful excuses from members of the tech community (both men and women) that “this is just how tech conferences are”, and “she should have a thicker skin”. The voices that suggest she shouldn’t have responded because the lewd comments were likely not directed at her seem to miss the point completely.</p>
            </blockquote>
            
            <p>But at least we’re talking about it. Soon after the event the organizers of PyCon put the Code of Conduct up on GitHub, a popular open source hosting service, and invited members of the community to collaborate on changes in light of recent events. The community responded by adding language to the policy that prohibits public shaming. This is not unreasonable, and probably desirable and consistent with a “innocent until proven guilty” mentality. But unless a clear, easy communication path is given to report incidents as quickly and efficiently as twitter, in a private manner is provided, this could also be seen as a measure to silence others who may feel the need to speak out about poor conduct, but for whatever reason (and there are many) do not feel comfortable addressing the individuals directly.</p>
            
            <p>The issue is not limited to sex or race, it is a larger one. Folks who are empowered by the status quo, whether they’re conscious of their priveledge or not, do not like the status quo challenged. Christie Koehler blogged about the incident <a href="http://subfictional.com/2013/03/22/bold-ideas-uttered-publicly/">from that perspective</a></p>
            
            <blockquote>
              <p>It’s not easy because the tactics available to those who oppose institutional oppression are limited and judged by the very institution that is oppressive.</p>
            
              <p>Those who benefit from the status quo, whether they realize it or not, have a vested interested in maintaining that status quo. That means working to ensure that any threat to it is rendered ineffectual. The best way to do that is to discredit the person who generated the threat. If the threat is the reporting of a transgressive act that the dominant social class enjoys with impunity, then the reaction is to attack the person who reported it.</p>
            
              <p>And when it comes down to it, the vast majority of the negative backlash against Richards and her company (and none that I’ve heard of towards PlayHaven, the company that actually fired the male developer and started the whole fiasco) comes down to defending the status quo with a passion. People will fight for their place of privilege. They will fight hard and they will fight dirty.</p>
            </blockquote>
            
            <p>And the very sordid nature of their fight will continue to prove unequivocally why we need to keep challenging the status quo until we create a world that is welcoming to all.</p>
            
            <p>More reading: <a href="http://www.forbes.com/sites/deannazandt/2013/03/22/why-asking-what-adria-richards-could-have-done-differently-is-the-wrong-question/">Why Asking What Adria Richards Could have done different is the wronge question</a><a href="http://freethoughtblogs.com/pharyngula/2013/03/22/adria-richards-did-everything-exactly-right/">Adria Richards did Everything Exactly Right</a></p>
          </article>
        </div>
        <div class='post'>
          <h1>
            <a href="/2013/03/we-are-the-medium-directors-cut/">We are the medium? (director's cut)</a>
          </h1>
          <aside>Posted at: March 20, 2013</aside>
          <article>
            <p>A couple weeks ago while reading Laurel’s, “The Six Elements and the Causal Relations Among Them” I had a bit of a moment at</p>
            
            <blockquote>
              <p>…the orthodox view of Aristotle’s definitions of spectacle and melody leaves out too much material. As scholars are wont to do, I will blame the vagaries of translation, figurative language, and mutations introduced by centuries of interpretation for this apparent lapse and proceed to advocate my own view.</p>
            
              <p>As I went through that passage I thought about Aristotle starting the discussion over 2000 years prior, but rather than focusing on Aristotle as a conscious, active agent, my brain took an interesting twist. For a brief moment the message itself, in this case, a conversation regarding the nature of drama, was a full fledged organism. Living, moving, evolving. It depended on Aristotle for survival, without a medium, a message is… I will leave that as an exercise for the reader, but regardless, to the message, Aristotle was no different than the cells that make up our body are to us. Sure, I know without the cells that make up my body I (whatever “I” is) wouldn’t exist, but I don’t particularly care WHICH cells are part of the structure that my “I” sits on and likewise, this message about drama was indifferent to the fact that Aristotle was Aristotle. In fact it probably didn’t even bat an ‘i’ when it hopped off of Aristotle onto its next host, morphing a bit in the process, and onward until at some point in its ongoing life, Laurel happened to pick it up and it experienced yet another one of countless moments of evolution.</p>
            </blockquote>
            
            <p>To the lifespan of an idea, at least the potential lifespan, a human life lasts a mere instant. Whether or not a message experiences a lifespan that long depends entirely on its survivable in the environment at the time. Yes, this sounds a lot like Richard Dawkins’ concept of a meme and no doubt the thoughts about memes that I had bouncing around in my head played some part in triggering this shift in perception from the human carrier as the source/center/agent to the message itself as the agent.</p>
            
            <p>And it was a humbling experience. To an immortal message human lives are blinking in and out of existences continually. And just as we shed cells that are replaced by new ones, so too do new brains fill in the gaps to hold the message aloft as old ones die off. If we view the message as a collection of juggling balls it is alive and well while the balls are in the air. Someone has to be there doing the juggling, but it doesn’t particularly matter to the message who that is, just as long as when the current entertainer reaches the end of his/her short time someone else is around to catch the balls before they fall. Viewed from above then, the planet appears to be covered in morphing, swelling sea of color, that upon closer inspection is made up of countless individual juggling balls seeming to float around and interact with each other on their own accord.</p>
            
            <p>And what if that’s all any one of us, as an individual is, just a medium for the message?</p>
            
            <p>I suppose depending on your frame of mind that could feel like a depressing thought. To me it wasn’t and isn’t. In fact, I would go far as to say I draw upon that metaphor to stay motivated and find meaning in my own life. Because if it is true that I am a medium, and the message is what matters, then I’m part of something bigger than I could ever grasp on my own. I have the potential to contribute to something that will have lasting effect on the world and while my individual life may be relatively short, it will not be without purpose.</p>
            
            <p>P.S. This turned out to be way more meaning-of-lifey than I had intended.</p>
            
            <p>P.P.S. 42</p>
          </article>
        </div>
        <div class='post'>
          <h1>
            <a href="/2013/03/about-time-idioms-about-time/">About Time: Idioms About Time</a>
          </h1>
          <aside>Posted at: March 19, 2013</aside>
          <article>
            <h3 id="tldr">TL;DR:</h3>
            
            <p>In the comments below please post, in your native language, or a non-English language in which you are fluent:</p>
            
            <ol>
              <li>how you would ask someone what time it is, and the literal word-for-word translation into English</li>
              <li>how you would ask someone where you are and the literal word-for-word translation into English</li>
            </ol>
            
            <p>I wonder if I should stop being surprised when topics I’ve discussed separately with separate people all start to relate. On Monday I talked about idioms in <a href="http://blogs.lt.vt.edu/ece2524s13">ECE2524</a> and made some comparisons between idioms in programming languages to idioms in spoken languages. As I thought about examples of idioms I noticed there were quite a lot about time:</p>
            
            <ul>
              <li>on time</li>
              <li>about time</li>
              <li>in time</li>
              <li>next time</li>
            </ul>
            
            <p>just to name a few (I’ve somewhat intentionally left out more complex examples like “a watched pot never boils”, “better late than never”, etc.). Today in <a href="http://gardnercampbell.wetpaint.com/page/vtclis13">vtclis13</a> we discussed <a href="http://en.wikipedia.org/wiki/Scott_McCloud">McCloud’s</a> “Time Frames”, a comic that explores the various ways time and motion are represented in comics. Inevitably we talked about the different ways of talking about and perceiving time, from the relativistic physical properties of the dimension, to our own personal perception of the passage of time, and how in both cases the rate of time can change based on the environment. Time is such a funny thing. We often talk about it as if we know what we’re talking about and we take various metrics for granted: In the U.S. what is it about taking 16 trips around the sun that makes someone ready to drive a car? 2 more orbits and we’re deemed ready to vote, and after a total of 21 orbits, after we have been on the Earth as it has traveled through about 19,740,000,000 kilometers relative to the sun, we are legally able to purchase alcohol.</p>
            
            <p>But if <a href="http://en.wikipedia.org/wiki/Einstein">Einstein’s</a><a href="http://en.wikipedia.org/wiki/Theory_of_relativity">forays into relativity</a> have taught us anything it is that nothing about time is absolute as we generally have an intuition for. And so I became curious about the idioms we use to talk about time and how they differ from culture to culture, language to language. <a href="https://twitter.com/GardnerCampbell">Dr. C</a> put my thought into a question: “Are idioms about time especially diverse?”. And so, through this little survey, I would like to explore that question by gathering some time idioms in the comments section, please refer back to the first paragraph for specific instructions!</p>
          </article>
        </div>
        <div class='post'>
          <h1>
            <a href="/2013/03/about-time/">About Time</a>
          </h1>
          <aside>Posted at: March 18, 2013</aside>
          <article>
            <p>Reading the “Time Frames” comic about depicting time in comics made me think about Brian Greene’s The Fabric of the Cosmos in which he uses several <a href="https://www.youtube.com/watch?v=cbaV4O98KfE#t=19m50s">metaphors and visualizations</a> to help explain the nature of this thing we call time. We tend to think we know what “now” is, and think of it as a snapshot of the current state of the world. That model suffices in our day-to-day lives quite nicely, but it isn’t a very good model of the concept of time on a universe-sized scale. Einstein’s famous Theory of relativity states that time and space are closely related, and that perception of both time and space is relative to the observer. The concept of “now” is also relative. Greene uses the metaphor of <a href="https://www.youtube.com/watch?v=cbaV4O98KfE#t=22m10s">a loaf of bread</a>, the long axis representing time, and a “slice” of the loaf representing an instant in time across a 2D universe. The angle at which the bread is sliced depends on an observer’s relative motion, with a maximum angle of 45 degrees corresponding to a maximum velocity of the speed of light. Two observers, Bob and Alice at different relative velocities would have slices at different angles, and so their “now” slices would intersect at some line in space. In Bob’s “now” some events in Alice’s “now” haven’t happened yet, they are in Bob’s “future”, while others are in Bob’s “past”. Time is an elusive concept, just when we think we know what we’re talking about we get hit with something like “my ‘now’ isn’t the same as your ‘now’”. It’s no wonder there are so many ways to depict its passage in the comic medium!</p>
            
            <p>On a slightly related tangent, the medium used can have some interesting affects on our perception of time and motion. In <a href="https://www.youtube.com/watch?v=mODqQvlrgIQ">this video</a>, recorded at 25 frames per second, a stream of falling water appears to freeze in time, or even flow backwards, when it interacts with sound waves at or near 25Hz. It’s not really an optical illusion, more of a media illusion.</p>
          </article>
        </div>
        <div class='post'>
          <h1>
            <a href="/2013/03/humans-in-the-loop/">Humans in the loop</a>
          </h1>
          <aside>Posted at: March 11, 2013</aside>
          <article>
            <p>Today’s hot article in the local twitterverse is a New York Times piece called <a href="http://www.nytimes.com/2013/03/11/technology/computer-algorithms-rely-increasingly-on-human-helpers.html?_r%3D0">Algorithms Get a Human Hand in Steering Web</a>. I discovered it from a tweet by <a href="https://twitter.com/GardnerCampbell">@GardnerCampell</a>, also <a href="https://twitter.com/mzphyz/status/311085754371674112">a beautiful retweet</a> by <a href="https://twitter.com/mzphyz/">@mzphyz</a>:</p>
            
            <blockquote>
              <p>Above all: Algorithms are human constructs, embodiments of our thought &amp; will.</p>
            
              <p>Which really sums up this entire post, so for the TL;DR crowd, you can stop reading right now! <a href="http://www.nytimes.com/2013/03/11/technology/computer-algorithms-rely-increasingly-on-human-helpers.html?_r%3D0">The article</a> mentions a number of examples of human-in-the-loop algorithms currently being employed on the internet, notably in Twitter’s search results and Google’s direct information blurbs (not sure what they call them, those little in-line sub-pages that show up for certain search terms, like a(ny) specific U.S. president, for example).</p>
            </blockquote>
            
            <p>What I found interesting was that the tone of the article seemed to suggest that the tasks humans were doing as part of the human-algorithm hybrid system were somehow fundamentally unique to our own abilities, something that computers just could not do. I’m not sure if this was then indented tone, but either way, I found myself disagreeing.</p>
            
            <blockquote>
              <p>Although algorithms are growing ever more powerful, fast and precise, the computers themselves are literal-minded, and context and nuance often elude them.</p>
            
              <p>True, but I would argue that our own brains are “literal-minded” as well, there are just layers and layers of algorithms running on our network of neurons that give the impression of something else (this ties in nicely to <a href="http://blogs.lt.vt.edu/castlebravo/2013/03/08/what-is-the-far-future-of-computing/">a post</a> by <a href="http://blogs.lt.vt.edu/castlebravo/">castlebravo</a> discussing <a href="http://blogs.lt.vt.edu/castlebravo/2013/03/08/what-is-the-far-future-of-computing/">what, fundamentally, computing is</a>). I think the underlying reasons we have humans in the loop are closely linked to the next sentence:</p>
            </blockquote>
            
            <blockquote>
              <p>Capable as these machines are, they are not always up to deciphering the ambiguity of human language and the mystery of reasoning.</p>
            
              <p>Not only is spoken language ambiguous, but we lack a solid understanding of reasoning, or how our brains work. And we, after all, are the ones programming the algorithms.</p>
            </blockquote>
            
            <p>In the case of the twitter search example, it struck me that all the human operator was doing was something like this:</p>
            
            <p>[code lang=”python”] if (search_term == ‘Big Bird’ and current_time is near(election_season) ): context = politics else context = ‘Sesame Street’ [/code]  which looks rather algorithmic, when written out as one. Granted, this would be after applying our uniquly qualified abilities to interpret search spikes, right?</p>
            
            <p>[code lang=”python”] if instantaneous_average_occurrence_of(‘Big Bird’) is significantly_greater_than(all_time_average(‘Big Bird’)): context = find_local_context(‘Big Bird’) else context = ‘Sesame Street’ [/code]  Of course the find_local_context is a bit of a black box right now, and significantly_greater_than may seem a bit fuzzy, but in both cases you could imagine defining a detailed algorithm for each of those tasks… if you have a good understanding of the thought process a human would go through to solve the problem.</p>
            
            <p>Ultimately, humans are only “good” at deducing context and nuance because of our years of accrued experience. We build a huge database of linked information and store it in the neural fabric of our minds. There isn’t really anything limiting us from giving current digital computers a similar ability, at least at a fundamental level, and theoretically, as our advances in hardware approach the capabilities of an “ideal computer” (one that can simulate all other machines), and our understanding of human psychology and neurology advances, we could simulate a very similar process to the one that goes on in our brains when deducing context and nuance.</p>
            
            <p>The current trend of adding humans into the loop to increase the user friendliness of online algorithms has more to do with our lack of understanding of human thought than with any technical limitations posed by computers.</p>
          </article>
        </div>
        <div class='post'>
          <h1>
            <a href="/2013/03/are-we-all-ice-skaters/">Are we all ice skaters?</a>
          </h1>
          <aside>Posted at: March 7, 2013</aside>
          <article>
            <p>Gliding through life, blissfully unaware that there is an entirely different world just below the surface.</p>
            
            <p>The times we do break through unexpectedly the shock is so much that it often kills us.</p>
            
            <p>And so we learn to fear thin ice. It is dangerous. It leads to death (some would say the ultimate price).</p>
            
            <p>When we do decide to tap into the world on the other side we carefully control our access using tools to drill a hole through the boundary.</p>
            
            <p>We remain on the surface, in our own element. Comfortable.</p>
            
            <p>We lower more tools through the chasm, to fish out the pieces of that underworld we are interested in, because we understand that some can help sustain our own life, on the surface.</p>
            
            <p>And when we have extracted what we think we need, we leave the opening to seal up.</p>
            
            <p>A distortion and blemish on our surface that skaters learn to avoid, because it can trip them.</p>
            
            <p>And even grow to resent those that broke the boundary as it now creates a more complicated environment for us to navigate smoothly.</p>
          </article>
        </div>
        <div class='post'>
          <h1>
            <a href="/2013/03/are-we-sacrificing-creativity-for-content/">Are we sacrificing creativity for content?</a>
          </h1>
          <aside>Posted at: March 4, 2013</aside>
          <article>
            <p>I decided to become an engineer, before even knowing what “engineering” was, because of a comment my 4th grade art teacher made regarding an art project. I’m pretty sure she meant it as a complement. The concept of “ is  math” is nothing new. From the mathematics of music, to the use of perspective in visual art, there is no escaping the mathematical nature of the universe. All art, no matter the medium, can be thought of as offering a different view of our underlying reality. A different way of looking at the equations, a way at looking at math without even realizing it’s math. Then why in the engineering curriculum is the emphasis all on the math? Sure, it’s important. Knowing the math can mean the difference between .
            Footnotes:
            ———-</p>
            
            <p>Though there is a beauty to the mathematics of this particular failure.</p>
          </article>
        </div>
        <div class='post'>
          <h1>
            <a href="/2013/03/ibreakit-ifixit/">iBreakit, iFixit</a>
          </h1>
          <aside>Posted at: March 4, 2013</aside>
          <article>
            <p>This past weekend ended up being the weekend of repairs as two lingering problems increased to a point that they could no longer be ignored:</p>
            
            <ol>
              <li>The drain pipe of my bathroom sink completely detached itself from the sink basin.</li>
              <li>
                <p>The aluminum frame on the display of my laptop began peeling away from the LCD panel to such an extend that I was concerned continued use could result in cracking the front glass.</p>
              </li>
              <li>The computer to be repaired</li>
              <li>mini screwdriver set</li>
              <li>Donut, preferably coconut</li>
              <li>Coffee</li>
              <li>working computer that can access <a href="http://ifixit.com">ifixit.com</a>
            </li>
              <li>5 minute epoxy</li>
              <li>T6 Torex screwdriver</li>
              <li>A reasonably heavy, flat object</li>
              <li>Stress relief</li>
            </ol>
            
            <p><a href="https://plus.google.com/photos/102713723625651639398/albums/5850411489752274785?authkey=CJ7uq8LJtfWTRA">Step-by-step image gallery</a>
              1. Follow the steps in the ifixit guide to remove the display assembly from the body of the laptop.
              2. Reset donut
              3. attempt to apply epoxy in gap between aluminum backing and display, apply pressure, wait for a couple hours
              4. reassemble laptop, power on and use
              5. determine that epoxy is not holding, either due to age, bad application due to limited access to the surface
              6. powerdown and re-disassemble laptop
              7. Using a heat gun to loosen the remaining adhesive around the display casing, gently pry off the aluminum backing completely
              8. This is a perfect opportunity to “pimp your mac” and add some sort of creative graphic behind the apple logo. All I could find was some engineering paper, which turned out somewhat ho-hum.
              9. attempt to remove old adhesive with acetone and/or mechanical force. give up.
              10. Working quickly, (it is 5 minute epoxy, after all) mix up a fresh batch of epoxy, apply intelligently around edge of display casing, choosing places that look least likely to cause problems if it runs over (e.g. avoid iSight camera housing)
              11. Carefully position aluminum backing back on display casing, press firmly and wipe away excess epoxy.
              12. Apply gentle pressure for 5-10 minutes, let cure for another hour or so before reassembly. [caption id=”attachment_290” align=”aligncenter” width=”300”][](https://lh6.googleusercontent.com/-tDw1UT85oCw/UTDWQJ-k6WI/AAAAAAAABNc/avdOcsnBcqY/s1028/IMG<em>20130301</em>103658.jpg)analog media is still relevant[/caption]
              13. Re-assemble.
              14. success!</p>
            
            <h2 id="footnotes">Footnotes:</h2>
            
            <p>take a genius to determine that a different bootloader from Apple’s default is not a virus.</p>
            
            <p>too late</p>
            
            <p>aside from possibly rendering my display useless</p>
            
            <p>if you have ever replaced a tire on your car, but freak out at the idea of fixing your own computer, briefly consider the consequences of a botched repair job on both. Statistically you are much more likely to die in a horrible, fiery crash as the result of a bad tire replacement than a botched attempt at re-gluing your laptop screen together. Just something to think about.</p>
            
            <p>wordpress fail: I could not figure out how to tell wordpress to use letters to “number” this ordered list without changing the style sheet for my theme. It could be user error, but I prefer to blame wordpress.</p>
          </article>
        </div>
        <div class='post'>
          <h1>
            <a href="/2013/02/creative-writing-technically/">Creative writing, technically</a>
          </h1>
          <aside>Posted at: February 27, 2013</aside>
          <article>
            <p>A number of recent conversations, combined with topics-of-interest in both <a href="https://blogs.lt.vt.edu/ece2524s13">ECE2524</a> and <a href="http://gardnercampbell.wetpaint.com/page/vtclis13">VTCLI</a>, followed by a chance encounter with an unfamiliar (to me) blogger’s <a href="http://craphound.com/?p=2171:ta">post</a> have all led me to believe I should write a bit about interface design and various tools available to aid in writing workflow.No matter our field, I’m willing to bet we all do some writing. Our writing workflow has undergon some changes since transitioning to the digital era, most notably for my interests is this quote from the <a href="http://craphound.com/?p=2171:ta">aforementioned blog post</a>: &gt; The author then introduces a <a href="http://bitbucketlabs.net/flashbake/">set of scripts</a> a colleague wrote as the response to a question on how to integrate version control into his writing process. The scripts are essentially a wrapper around <a href="http://git-scm.com/video/what-is-git">git</a>, a popular version control system used by software developers and originally designed to meet the needs of a massively distributed collaborative projects, namely <a href="http://www.kernel.org/">the Linux kernel</a>. What’s really great about this (aside from the clear awesomeness of a sci-fi author collaborating with a <a href="http://thecommandline.net/">techie blogger/podcaster</a> to create a tool that is useful and usable by writers using tools that that are useful and usable by software developers) is that it brings into clear focus some thoughts I wanted to get out last semester about the benefits of writing in a plain text format. This gets back to one of the recent conversations that also ties into all of this: I was talking to a friend of mine, another grad student in a STEM field, and we were discussing the unfortunate prevalence of the use of MS Word for scientific papers. I don’t want to get into a long discussion of the demerits of MS Word in general, but suffice it to say, if you are interested in producing a professional quality paper, and enjoy the experience of shooting yourself in both foot followed by running a marathon, then by all means, use MS Word. There are also a number of excuses of questionable validity that people use to defend their MS Word usage in scientific writing. The ones that are often brought up often involve the need to collaborate with other authors who are also using MS Word. Now run that marathon backwards while juggling flaming torches. I should point out I don’t want to just pick on MS Word here, the same goes for Apple’s Pages or any large software package that tries to be the solution to all your writing needs. I will hence forth refer to this problematic piece of software generically as a “Word Processor”, capitalized to reinforce the idea that I am indeed referring to a number of specific widely used tools. The conversation led to user interfaces, and the alleged intuitiveness of a modern Word Processor, compared to simple, yet powerful text editor such as <a href="http://www.gnu.org/software/emacs/">emac</a>s or <a href="http://www.vim.org/index.php">vim</a>. Out of that, my friend discovered a post on a neuroscience blog about <a href="http://theness.com/neurologicablog/index.php/neuroscience-of-user-friendly/">user friendly user interfaces</a> that did a nice job putting into writing thoughts that I had been trying to verbalize during our discussion. Namely that the supposed intuitiveness of a Word Processor to “new” users is largely a factor of familiarity rather than any innate intuitiveness to the interface. Once your learn what the symbols mean and where the numerous menu items are that you need to access then it all seems just dandy. Until they go and <a href="http://en.wikipedia.org/wiki/History_of_Microsoft_Word">change the interface</a> on you. I could and probably should write an entire post on ALL the benefits of adopting a plain-text workflow, and the benefits of using one text editor that you know well for all your writing needs, from scientific papers, to blog, presentations and emails (how many people ever stop to think why it is acceptable and normal to have to learn a new user interface for each different writing task, even though fundamentally the actual work is all the same?). The key benefit I want to highlight here is the one that made it possible for the collaborative effort I mentioned towards the top to take place. By writing in a plain text format, you immediately have the ability to use the enormous wealth of tools that have been developed throughout the history of computing that work with plain text. If our earlier mentioned hero had been doing his writing in a Word Processor, it would have been nearly impossible for his friend to piece together a tool for him that allows him to regain something that was lost with the transition away from a paper workflow, a tool that can “illuminate the creative process in a way that often reveals the hidden stories”, and in many ways goes beyond what was possible or convenient with the paper workflow. What tools do you use to track your writing process? Do they allow you to go back to any earlier revision, or allow you to easily discover what recent blog’s you had read, what your mood and what the weather was when you wrote a particular passage? Do you use a tool with an interface that is a constant distraction, or one that is hardly noticeable and lets you focus on what actually matters: the words on the page. If not, then why?</p>
          </article>
        </div>
        <div class='post'>
          <h1>
            <a href="/2013/02/i-am-a-selfish-git-a-bit-on-my-teaching-philosophy/">I am a Selfish Git: A bit on my teaching philosophy</a>
          </h1>
          <aside>Posted at: February 25, 2013</aside>
          <article>
            <p>A common observation I encounter from people who have taken my class is that there is less structure in the assignments than they are used to, and oftentimes less than they would like. A consequence of this is that participants do a lot of searching the web for tidbits on syntax and program idioms for the language <em>du jour</em>, a process that can take time with the wealth of information that is returned by a simple google search. I could track down some research that shows the benefit of this “look it up yourself” approach, and it would all be valid and it is one of the reasons I structure assignments the way I do, but there is another reason. A more selfish reason. Throughout the term I’ll assign a series of assignments. Details are tweaked each semester but the general outline is something like:</p>
            
            <ul>
              <li>read in lines of numbers, one per line, do something with them and write out a result number.</li>
              <li>read in lines of structured data, do something with them, write out lines of structured data</li>
              <li>spawn a child process, or two, connect them with a pipe (this year I will probably integrate the “read in lines” idiom into this assignment since I like it so much)</li>
            </ul>
            
            <p>I’ve done each of these myself of course, and tweaked my own solutions from year to year and have found a structure for each that I think works well, is easy to read and is as simple as possible. Often times my solutions use fewer lines of code than some of the solutions I receive, which admittedly make my estimates of how long a particular assignment will be inaccurate. I know some of the assignments end up taking a lot longer than I anticipate for some, and this can be extremely frustrating, especially since I know everyone’s time is a precious commodity that must be partitioned across other classes and personal time too (you <em>are_making time for play, aren’t you?). I could provide more details in the write-ups. I could say “I tried algorithm X a number of ways: A, B and C, and settled on B because P, Q and R”. It would save those completing the assignments time and it would save me time, because on average the results I’d get back for grading would take up fewer lines of code and be more familiar to me. And that is why I don’t. If I wrote in the assignment and said “for part A, use method B in conjunction with idiom X and you can complete this part in 3 lines” then I can guarantee you that around 99% of the 60 assignments I received back used method B in conjunction with idiom X in only 3 lines of code. It would be much easier to evaluate: I’d be familiar with the most common errors when using method B in conjunction with idiom X and would have made spotting them quickly a reflexive response. But I wouldn’t learn a thing. Let me tell you a secret. Sure, I enjoy seeing others learn and explore new ideas and get excited when they discover they can write something in 10 lines in Python that took them 30 in C. I really do. But that’s not the only reason I teach. I teach because I learn a tremendous amount from the process myself. In fact, all that tweaking I said I’ve done to my solutions? That was done in response to reviewing a diverse (sometimes _very_diverse) set of solutions to the same problem. Often times I’ll get solutions written in a way I would never have used solving the problem myself, and my first reaction is something like “why does this even work?” And then I’ll look at it a little closer (often times using a fair amount of googling myself to find other similar examples) until I understand the implementation and form some opinion about it. There are plenty of times that I’ll get a solution handed to me that I think is cleaner, more elegant and simpler than my own, and so I’ll incorporate what I learned into my future solutions (and let’s not forget back into my own work as well, a topic for another post). And I’ll learn something new. And that makes me happy. I really like learning new things (thank goodness for that, given how long I’ve been in school!), and I have learned _so</em> much over the past couple years that I’ve been teaching. Possibly more than what I’ve learned in all the classes I’ve taken during my graduate career (different things for sure, which makes it difficult to compare amount, but still, you get the idea). To be sure, there is a balance, and part of my own learning process has been to find out that sweat spot between unstructured free-style assignments (“Write a program that does X with input B. Ready go!”) and an enumerated list of steps that will gently guide a traveler from an empty text file to a working program that meets all the specs. I think I’ve been zeroing in on the balance, and the feedback I get from blogs as well as the assignments themselves is really helpful. So keep writing, and keep a healthy does of skepticism regarding my philosophy. And ask questions!  [caption id=”” align=”aligncenter” width=”337”]<a href="http://xkcd.com/118/">50 Ways</a>[/caption]</p>
          </article>
        </div>
        <div class='post'>
          <h1>
            <a href="/2013/02/a-comment-on-a-comment-on-commenting/">A Comment on "A comment on commenting"</a>
          </h1>
          <aside>Posted at: February 18, 2013</aside>
          <article>
            <p>In his post <a href="https://blogs.lt.vt.edu/leonp/2013/02/11/annoyances-of-commenting/">A comment on commenting</a>, <a href="https://blogs.lt.vt.edu/leonp/">leon.pham</a> commented on the annoyance of remembering different commenting syntax in different langauges. It’s true, it is a lot to keep track of. Luckily, if you use a good text editor, such as emacs or vim you can offload the task of remembering what syntax to use to the editor itself. For instance emacs has <a href="http://www.emacswiki.org/emacs/CommentingCode">two commands</a> to aid in creating comments: one to block off a highlighted region in comments, and another to add an end of line comment. Once you learn the command for each (adding an end-of-line comment defaults to M-; in emacs, (where M is the “meta” key, or “Alt” on most keyboars) but of course you could map it to anything you want), that’s it. The editor is generally is smart enough to know what language you are current writing in (and of course you can override it when you need to), and so the universal “add a comment” command that you learn once will always add a comment in the proper syntax for the language you are currently editing! Just another motivation to learn one editor and learn it well! I will leave it as an exercise for the vim-using reader to post information for the equivilant command in vim!</p>
          </article>
        </div>
        <div class='post'>
          <h1>
            <a href="/2013/02/blasphemy-drmed-games-on-linux/">Blasphemy?: DRMed Games on Linux</a>
          </h1>
          <aside>Posted at: February 18, 2013</aside>
          <article>
            <p>The interwebz have been all atwitter the past month or so with <a href="http://www.wired.com/gamelife/2013/02/steam-linux/">Valve’s announcement</a> of the porting of their Steam gaming service to the GNU/Linux platform. Many Linux users were thrilled about the announcement and saw it as a sign that Linux was breaking out of the small niche culture of hackers to more mainstream folk who just want to turn there computer on and play a game. To be fair, Linux is not without a large number of free (both as in <a href="http://en.wikipedia.org/wiki/Gratis_versus_libre">beer and as in speech</a>) <a href="https://libregamewiki.org/Main_Page">games already</a>, but the announcement of a major (are they? I actually only heard of Valve and Steam because of the Linux announcement) gaming company moving to the platform as seen by some as legitimizing the OS to the masses. It certainly gives everyone something to talk about.</p>
            
            <p>I consider myself more of a pragmatic when it comes to the philosophical debate surrounding free (for those familiar, the debate mostly deals with libre software. English has many deficiencies, one of which is the multiple meanings of the word “free”. In general free software supporters do support the idea of paying for software and believe that people should be able to make money off of the software they write). I think free software is a great ideal to strive for, and certainly for mission critical software I believe it is important to have the freedom to view and modify the source code. As I brought up in <a href="http://gardnercampbell.wetpaint.com/page/vtclis13">vtcli</a> earlier this semester, as an example it is important to have the freedom to confirm that the incognito mode of your web browser really is doing what it says it is and not storing or sharing your browsing information (as an aside to that, I erroneously claimed that Chrome was open source, it is not, however, it theoretically uses the same code-base as <a href="http://www.chromium.org/">Chromium</a>, which is open source, and happens to be the browser I use both when in Linux and OS X. I highly encourage any users of Chrome to switch to Chromium for the open sourced goodness it provides, including the ability to confirm that incognito mode really is incognito). That being said, if there’s a great game I like I am not terribly concerned with not being able to look at or distribute the source code, though I certainly would encourage game developers to release their code under one of the many open source licenses.</p>
            
            <p>It is interesting to note that free software evangelist Richard Stallman himself <a href="http://www.gnu.org/philosophy/nonfree-games.html">isn’t ALL doom and gloom</a> about the news. Though he certainly isn’t thrilled and encourages people to try out any of the free games that are available, he does see the move as a possible motivator for some people to ditch their non-free OSes completely if gaming had been the only thing holding them back.</p>
            
            <blockquote>
              <p>I installed Steam on my <a href="https://www.archlinux.org/">Arch Linux</a> install last week and so far have tried out <a href="http://store.steampowered.com/app/107100/">Bastion</a>, <a href="http://store.steampowered.com/app/209790/">Splice</a> and <a href="http://store.steampowered.com/app/22000/">The World of Goo</a>. All work very well and have been fun (I had played World of Goo before both on OS X and Android, it is fun on any platform!). Offically, Arch Linux isn’t supported but after adding a couple of the libraries and font packages <a href="https://wiki.archlinux.org/index.php/Steam">mentioned on the wiki</a> everything worked like a charm. One down side that Stallman failed to mention in his response was the fact that it is much easier for me to spend money on games now that I don’t need to switch over to OS X to run them.</p>
            </blockquote>
          </article>
        </div>
        <div class='post'>
          <h1>
            <a href="/2013/02/git-games-and-meta-moments/">Git Games and Meta Moments</a>
          </h1>
          <aside>Posted at: February 17, 2013</aside>
          <article>
            <p>I had a bit of a meta moment while swimming today. I have a lot of good moments while swimming, probably because it’s a chance for my mind to wander. That’s probably a good argument to go more often than I did this past week (1 out of 6 possible practice days!). But I digress.</p>
            
            <p>Yesterday I was introduced to a <a href="http://pcottle.github.com/learnGitBranching/">game of sorts</a> to help learn some concepts used by <a href="http://git-scm.com/about">git</a>. For those of you who don’t know, git is a versioning control system that has gained quit a bit of popularity over the past few years, especially in the open source community. I had been using it myself for my own projects, but mainly at a very simplistic level.</p>
            
            <p>At one level, a versioning control system (VCS), of which git is one of many, is a tool to facilitate documenting the changes of… well, a document. Historically these systems were develped by software designers to both document changes and provide an easy path to revert to older versions of source code. Later, similar concepts were implemented in modern word processors (with limited scope and power due to the restrictive nature, essentially the traditional method of tracking edits from the pen and paper days was ported over to the electronic medium without much change).</p>
            
            <p>One thing that became much more clear to me after trying out the git game was that while providing logical “snapshots” of a project that can be used as a return point if somethign goes astray in the future, git is creating a history of the project, a history that tells a story. But unlike other histories you may be familiar with, the history generated by git can be rewritten to change the past.</p>
            
            <p>What had alluded me up until this point was what motivation one might have to rewrite history. I figured, you make changes, commit them to the project, those changes get recorded, what more would you need? Well, it turns out that with the ability to rewrite history, git makes it incredibly easy to do certain types of edits on your data and allows an author to use git more as a tool for trying out new, possibly risky ideas, or take off on a tangent while always providing a clear path back to a ground point.</p>
            
            <p>The details of what these types of edits are are important, but after I began writing them up I realized I was losing sight of my original reason for writing this post! Luckily, I have been using git to track changes to this document, and created a branch for each of the examples I thought would be useful. I’m going to leave them out of the final document for now, but they exist in my history, and since I will post this project to github, you are free to take a look!</p>
            
            <p>What I thought about while swimming, after the git game helped me understand why rewriting history could be so useful, and how the history itself could be used, was that since I’m using git to manage the files for ECE2524, I could also use it guide future semesters of the course. Every time I add a new set of lecture notes, or add a new assignment, I make a commit to a git repo containing all the files I’ve used so far. That is also recording the order in which topics are introduced to the class, so I’m generating an outline for the semester just by nature of using git for your regular garden variety versioning control.</p>
            
            <p>But I had an hour and a half to occupy my brain while I swam back and forth, so the wheels kept turning. We use git for class, as those of you in it know, because it is an important tool for software development and happens to be a particularly Unix-y tool to boot. The Unix-i-ness of git is something I will leave for discussion in class tomorrow (oh, the suspense!). We use git, but it is a complicated tool to learn, even though what it is doing is quite simple, once you <a href="http://en.wikipedia.org/wiki/Grok">grok</a> it, something that doesn’t always happen quickly, and never as quickly as you would like.</p>
            
            <p>But the information tracking ideas from git can be related to the process we go through in class, which can also be related to the discussion on working memory vs. long-term memory we had in <a href="http://gardnercampbell.wetpaint.com/page/vtclis13">vtlci</a>. The process of learning new things involves some experimentation and a lot of data filtering. We have a lot of information available to us, the culmination of which can be thought of as the contents of our “working directory” in git terms. As we individually work through the information and inspect it through our own lens we commit pieces of it to our memory, our repository. Though we’re not actively doing it, there is a log associated with this process. It is not as precise as something stored on a computer, of course, but looking back on the past few days we can recall things like “concept X made a lot more sense to me after I understood hypothesis Y, which became clear after working through exercise Z.”</p>
            
            <p>What if we were more conscious of this process in class, and even made an effort to map it more directly to the concept of using git? For instance, one versioning control concept we’ll start to explore tomorrow is branching and merging.</p>
            
            <p>A branch can be thought of as a temporary deviation away from the main story line. In fact, in my first paragraph I went off on a bit of a tangent about my tendency to let my mind wander while swimming. That could be thought of as a branch away from the main topic, which (I promise) is about using git to map the journey we take to learn to use git. In fact, I switched to a new branch in git when I began writing those sentences, and then merged them back into the main conversation when I was done.</p>
            
            <p>What if the class were split up into groups, and each group worked on one aspect of learning to use git’s branch and merge functionality. For instances, Group 1 might play the git game, while group 2 might read about how git represents and references data and what is going on under the hood. At that point, the collective commit knowledge of the class will have split into two branches. One branch with more of a pragmatic grasp of “this is how I do a branch and merge” and another branch with a better understanding of “this is how a branch and a merge is implemented by git”. Then, the following week, both groups would come back together and share what each learned. The two groups will have just “merged” their knowledge and everyone should have a better understanding of how to conduct a branch and a merge, and also what is going on with the underlying data structure when they do one.</p>
            
            <p>Oh, and by the way, when writing that last paragraph I created two new branches: one named “group1” and it contained the description of what the hypothetical group1 would do, and another called “group2” which contained the sentance describing that group’s task. Then I merged the two back into the master branch, reformated the paragraph and add a summary. Check out this history on github!</p>
            
            <p>So this whole process got me thinking. Does thinkging about meta thoughts make it easier or more likely to think about meta thoughts in the future? And likewise, does it make it easier to draw comparisons between seemingly unrelated processes, such as learning new ideas, and software development, when you have a process and a vocabulary to describe the process of each? <a href="http://bit.ly/YAAQ7a">I am a strange loop</a>.</p>
          </article>
        </div>
        <div class='post'>
          <h1>
            <a href="/2013/02/does-awareness-of-our-limitations-aid-in-overcoming-them/">Does awareness of our limitations aid in overcoming them?</a>
          </h1>
          <aside>Posted at: February 6, 2013</aside>
          <article>
            <p>A couple of thoughts have been bouncing around in my head while reading. First, while reading <em><a href="http://www.theatlantic.com/magazine/archive/1945/07/as-we-may-think/303881/">As We May Think</a>_by Bush, but repeatedly with other sources, I was reminded of a thought I often have when reading science ficture written in the 50s, around the same time Vannevar Bush wrote _As We May Think</em>. While on many levels the predictions of the future turned out to be quite accurate, there are notable exceptions that jump out at me while reading. A really good example that illustrates my point is Isaac Asimov’s Foundation series. The series is somewhat unique in that it covers a huge expanse of time in the fictional world, over 20,000 years if all the short stories and novels written by other authors after Asimov’s death are taken into account, and was written over several decades in standard non-fictional Earth time: the four stories that made up the first published book in the series were written between 1942 and 1944. Asimov thought he was done with the series after writing two stories in 1948 and 1949 and went on to do other things for 30 years. After much continued pressure from fans and friends he published the 6th book in the series in 1982 and the 7th in 1986. Three things struck me while reading the first part of the series, written in the 40s and 50s:</p>
            
            <ul>
              <li>It was generally assumed that nuclear power was the energy of the future. The logical extrapolation was nuclear powered wrist-watches (ok, actually, I did read a compelling article fairly recently revisiting micro-atomic generators using minuscule amounts of radioactive materials to agitate a pizo-electric element to produce electricity, so maybe this wasn’t so far off the mark)</li>
              <li>While we would have space ships capable of faster-than-light travel (hyperspace!), the calculations to perform jumps and ensure that the trajectory didn’t travel too near the gravitational effects of a star were done by a human, by hand. Particularly long jumps took the better part of a day to calculate and verify before it was deemed safe to tell the ship to execute the maneuver which itself would only take a fraction of a second.</li>
              <li>There were no women whatsoever in any type of leadership role. We could say the same of ethnic minorities, non-heterosexual and non-cisgendered people as well, but we will give Asimov the benefit of the doubt and acknowledge that the U.S. was (at least visibly) much less diverse than it is today. But surely he knew about the existence of women.</li>
            </ul>
            
            <p>These are little things you get used to when reading science fiction of the time. I think perhaps most interesting is that while it is common to extrapolate technology into the future with reasonably accuracy, the social structures that will exist 10,000 years from now are remarkably similar to those of the current time, if science fiction authors have anything to say about it. As I mentioned, the 6th book, Foundation’s Edge was published in 1982. Within the first page or so it was revealed without fanfare that the mayor of Terminus, politically the (quasi) central planet of The Foundation (despite it being on the outskirts of the colonized worlds), is currently a woman. Also, due to much research and development the latest spaceships have a new feature: hyperjumps are calculated in a matter of seconds by on-board computers. Also the old nuclear technology has been replaced by state-of-the-art zero-point-energy extraction (if I recall correctly, it’s been a while since I read the books!) providing a nearly unexhaustable energy source to power your jaunts around the universe. The changes, while artfully worked into the narrative and coherently worked into the fictional universe that had first been described over 30 years prior, still jumped out at the casual reader. I bring this up by no means to diminish Asimov’s work, or him personally (I’m a huge fan, having read and enjoyed just about every book he’s written at this point), but rather to suggest that we has a species have some fundamental limitations in regards to predicting the future. We view the future through a lens designed by history and crafted in the present. While it is all too natural for us to extrapolate existing technology and social dynamics arbitrarily far into the future, and while that leads to some really fascinating scenarios, making significant conceptual leaps (such as the one Ada Lovelace is attributed to making) is something much more difficult and happens much less frequently. What I wonder though, is after a long history of learning from our shortsightedness in some instances (and acknowledging our forsightedness in others), can we overcome this limitation? Are we now, compared to the 1950s, better able to make conceptual leaps and imagine technology and social structures that are fundamentally different from those of the present simply because we are aware that we tend to make certain kinds of assumptions? Why would a woman even WANT to be mayor of a politically powerful planet?</p>
          </article>
        </div>
        <div class='post'>
          <h1>
            <a href="/2013/02/on-farming-the-internet-and-funny-hats/">On Farming, the Internet and Funny Hats</a>
          </h1>
          <aside>Posted at: February 4, 2013</aside>
          <article>
            <h3 id="this-is-a-picture-of-me-wearing-a-hat-i-made">This is a picture of me wearing a hat I made:</h3>
            
            <p>[caption id=”attachment_252” align=”aligncenter” width=”300”][](https://blogs.lt.vt.edu/shebang/files/2013/02/meinhat.jpg) A “Scott Pilgrim” hat I made.[/caption] It was made from the same pattern used to make the hat used in the movie Scott Pilgrim vs. The World: The woman who did the work of adapting the hat drawn in the comic to something that could be made for a movie made her pattern available (for a small fee) on <a href="www.ravelry.com">ravelry.com</a>, a social network for knitters and crocheters. I’m writing this post right after finishing a dinner which included mushroom leek risotto which I made while reading (risotto the _real _way involves a lot of stirring and pour in broth a little at a time) _Bringing it to the Table_by Wendell Berry. The book is a collection of essays Berry wrote over several decades on the topic of farming and food (Not entirely incidentally, Wendell Berry caused a stir and inadvertently started a flame war after writing his essay “Why I am Not Going to Buy a Computer” back in 1987). I ate my risotto out of a bowl that was hand made, though I don’t know by whom, that I picked out at the Empty Bowls charity event I attended on campus last semester. Along with the risotto I had some lentil soup (which I’m sorry to say only came from the organic section of Food Lion) served in a bowl that was hand made by a friend. [](https://blogs.lt.vt.edu/shebang/files/2013/02/notemptybowls.jpg)</p>
            
            <p>In his 1986 essay “A Defense of the Family Farm”, Berry says &gt; People like to make things. We feel a deeper sense of connection to others when we use tools and wear clothing made by someone’s hands. In this essay Berry is cautioning against losing this rich tradition embodied in the family farm to the industrial agriculture complex. Now, in 2013, it is sad to say is cautionary foresight was well placed. Especially in the United States, and increasingly elsewhere as our “efficient” agricultural methods spread, we have become a society that is nearly thoroughly disconnected in all the ways that matter from the one thing that our very survival depends on: our food. In his essay “As We May Think”, Bush asked “What are the scientists to do next”. After the end of a scientific enlightenment of sorts, brought on by the War he asked if we could turn the tremendous scientific energy towards something more constructive. One of the many results of the technological advancements made during the war was a radical transformation in the way we grow (and subsequently think about) our food. It had been know for some time that plants needed at least nitrogen, phosphorous and potassium (N-P-K) to grow (it turns out to grow _well _they need much more, but at the time, we were patting ourselves on the back for unlocking the mysteries of plant life). Once the war ended there was an abundance of nitrogen (a component of TNT) that needed to be put to good use. The need was so great that it was made available to farmers (in the form of ammonia) for cheap, so cheap that it made economic sense to switch to this commercial product instead of continue with the tried and true method of spreading manure. Along with this change came others. Because synthetic fertilizers could be produced and transported and spread in large quantities, and due to changes in the Farm Bill to promote food security farm sizes grew and crop diversity shrank. With less diversity less skill was needed and the number of family farms in the U.S.  have given artisans and people wanting to buy artisanal products a means to connect directly, without going through a middleman, eliminating an undesirable layer of indirection between the products we use and the people who made them. Can the Internet help us reconnect with what we truly value: each other?</p>
          </article>
        </div>
        <div class='post'>
          <h1>
            <a href="/2013/01/stranger-in-a-commonplace-land/">Stranger in a Commonplace Land</a>
          </h1>
          <aside>Posted at: January 30, 2013</aside>
          <article>
            <p>As I began reading the two introduction essays by Janet Murray and Lev Manovich to The New Media Reader I first was a bit overwhelmed with the length of each.  This immediately made me think of an article that was reverenced in the <a href="http://www.guardian.co.uk/technology/2010/jun/20/internet-everything-need-to-know">previous reading</a>, “<a href="http://www.theatlantic.com/magazine/archive/2008/07/is-google-making-us-stupid/306868/">Is Google Making us stupid?</a>”: was the fact that I initially gawked at so many words and pages a result of my immersion in a world of near-instant informational gratification and 140 character thoughts? The thing is, I have no problems whatsoever reading a 500 page novel, if it’s interesting and indeed there were certainly pieces of each introduction piece that jumped out at me: &gt; The concept of defining a unifying model that describes all of creativity is quite appealing to me.  ”The world as a problem” seems at the same time both a grossly over simplified, and a perfectly succinct description of creativity  as I see it, and particular to my field of engineering.  Murray than goes on to draw contrasts between “engineers” and “disciplinary humanists” which particularly piqued my interest because I often feel like an outsider looking in when talking to other engineers about humanistic concepts, but also an outsider when trying to explain how I see engineering to “disciplinary humanists”.   The second essay   provided a nugget that helped direct my thoughts on this curious feeling of duplicity &gt; Whether we like it or not, this is becoming the reality.  We now get our books, music, movies and even long distance personal interaction mediated by a computer and the interface they provide us.  The thing is, any good engineer knows that if a piece of technology is doing its job, it should be transparent to the user.  While reading both of these essays I found myself thinking: why are we trying to force so much focus on the “new” in “new media”?  Is our doing so an indication that we as engineers still have more work to do to make the current technology transparent (I think we do) or is society so transfixed by “new” technology for some other reason that we are refusing to let it become as transparent as it could be? Manovich, I think would disagree on that point, at least in the U.S. as one of his arguments for the late start of new media exhibits in the U.S. was in part do to the rapid assimilation of new technology so that it became ubiquitous before we had time to reflect upon its potential impacts.  As I’m writing that I feel myself rethinking my own view, because I don’t want to suggest that we not reflect upon the impact of technology that we now take for granted, in fact I have often felt we need to do much more reflecting, and I agree wholeheartedly that we have adopted some technologies that have drastically changed our day-to-day lives (who plans things in advance any more when you can just text your friends last minute to find out where people are?) that may consequences far extending the superficial sphere of their direct influences (if we don’t plan our days, are we losing our skill at thinking into the future and acting accordingly in general? Are we becoming a species obsessed with living in the moment and unable to live any other way?) I’m in danger of rambling now, but I now have a better understanding of why I found it difficult to focus on the entirety of both essays.  Everything around each nugget either seemed redundant, overly descriptive, or a distraction from the thought process that had started forming in my head.  If good technology should be transparent to the user, why are we spending so much time worrying about it? And what are the consequences if we don’t?</p>
          </article>
        </div>
        <div class='post'>
          <h1>
            <a href="/2013/01/its-a-feature-not-a-bug/">It's a Feature, not a Bug</a>
          </h1>
          <aside>Posted at: January 28, 2013</aside>
          <article>
            <p>In his article <a href="http://www.guardian.co.uk/technology/2010/jun/20/internet-everything-need-to-know">The internet: Everything you ever need to know</a>, John Naughton lists nine key concepts about the Internet to help us understand that profound impact it is having, and will continue to have, on our lives.  Reading number 3 “DISRUPTION IS A FEATURE, NOT A BUG” I found myself drawing parallels to the design of the Internet and the design of the Unix operating system. The similarities are no accident, as the history of Unix and the Internet became closely intertwined after DARPA’s 1980 decisions that the BSD Unix team would implement the brand new TCP/IP stack which controls how data packets are routed between machines on the Internet.  Of the design of the Internet, Naughton says &gt; The result of this was a general purpose network from which sprang a diverse collection of services and applications (including the World Wide Web, see item number 2), some of which began disrupting established industries. This disruption, Naughton argues, is a desirable effect, though not necessarily to the  existing music labels and media distributor behemoths such Warner Music Group and others that are having to drastically rethink their business models to remain relevant in the era of peer-to-peer data networks. Like the Internet, Unix was designed around a number of axioms, the relevant ones being that the system should provide a core set of well defined, simple system calls for interacting with hardware and data, and that passing data between processes should be as easy as possible.  As a result of these design choices an environment of diverse programs, each of which “do one thing and one thing well” and can easily share data with other programs has developed.  The end result of this can be thought of as a direct contrast to this description by Eric Raymond in his book <a href="http://www.catb.org/esr/writings/taoup/html/ch01s05.html">The Art of Unix Programming</a>: &gt; Unix users, on the other hand, have consistently been able to complete tasks that were never anticipated by the original designers, a key factor in its continued relevance.  As technology changes and users demand new tools and applications developers on other systems have to work a lot harder and are at the mercy of the system developers to make changes to the underlying system to continue to produce cutting edge software solutions.  On a Unix system it is just as easy to copy a file from your USB  flash drive to your hard drive as it is to copy a file from your harddrive to a machine on the other side of the world and it is just as easy to stream video data from a local file as it is from a server on the internet.  The design has lead to a remarkable, even surprising degree of flexibility and usefulness:</p>
            
            <blockquote>
              <p>Unix has supported a mind-bogglingly wide spectrum of uses. No other operating system has shone simultaneously as a research vehicle, a friendly host for technical custom applications, a platform for commercial-off-the-shelf business software, and a vital component technology of the Internet. - Eric Raymond, The Art of Unix Programming
             Like the Internet, the simple infrastructure layer by Unix (and its present-day incarnations such as BSD and GNU/Linux) provides an environment for nearly unlimited creativity, one which continues to surprise users and non-users alike with its ability to solve problems and implement ideas that a year ago didn’t even exist.  And likewise, the disruption it has caused has been a boon to individuals: The Linux based Android operating system is running on <a href="http://www.gartner.com/newsroom/id/2237315">over half the world’s smart phones</a> and <a href="http://en.wikipedia.org/wiki/Mobile_operating_system#Market_share">quickly overtoke</a> more established contenders such as Apple’s iOS.  Linux has already disrupted the <a href="http://softwareandunicycles.wordpress.com/2010/07/31/does-desktop-linux-need-a-killer-app/">server market, the embedded market and most recently the phone market</a>.  It remains to be seen whether or not it will have a noticeable impact on Microsoft’s stranglehold on the desktop market, unless you consider Apple’s Unix derived OS X as an example. the end.</p>
            </blockquote>
          </article>
        </div>
        <div class='post'>
          <h1>
            <a href="/2012/12/semester-in-review/">Semester in Review</a>
          </h1>
          <aside>Posted at: December 24, 2012</aside>
          <article>
            <p>Well, as I’m about 6 hours in* into a 14 hour bus+train journey to Massachusetts I figured this would be a good time to reflect and respond to the past semester which seems to have flown bye.</p>
            
            <h1 id="the-blogs">The Blogs</h1>
            
            <p>I <em>really_enjoyed the blog assignment. Even though I wasn’t able to write a reply to every post I felt a lot more in sync with how the class as a whole was progressing. When there was confusion or frustration regarding a particular assignment, or just towards the class in general, I was able to respond quickly (I hope!). I feel I learned much more about how the material in ECE2524 was connected both to other courses and to events that interested you outside of coursework (open source gaming, personal server setups, commentary on Ubuntu as a general purpose OS). There are a couple things I plan to change with the blog assignment with the end goal of adding a little more structure to the syndicated class blog, and hopefully encouraging more of a discussion.
              - enforce “category” and “tag” rules. If you look down the right sidebar of the <a href="http://blogs.lt.vt.edu/ece2524">mother blog</a>you will see a list of all the categories posts have been made under. The current list is too long and not focused enough to be of any amount of use to someone trying to sift through the many posts for a particular topic. Most of the words used for “categories” should have been “tags” instead, so spending a little time up front talking about the difference I think would be helpful in the long-term organization and usefulness as an archival tool of the blog. Some categories I’ve thought of are:
                - Introspective: reflect on the course itself, whether it be assignments, discussions or structure.
                - Extrospective: explore connections between course material and using *nix systems or applying Unix design philosophy to other courses or events.
                - Social Network: comment on and continue the discussion taking place at VTLUUG and VTCSEC meetings.
                - Instructional: Discussing personal setups and/or workflows. Posts here will have sort of a “tutorial” or “howto” feel.
            There are a couple optional assignments I want to offer that would be linked to blog posts:
                - Learn a Language: There are many benefits to learning a new programming language. From _The Pragmatic Programmer</em>, Tip #8 “Invest Regularly in Your Knowledge Portfolio”:
            &gt; Throughout the semester those opting to do this assignment would document their progress with their language of choice and share any new ways of thinking or problem solving gained by thinking outside their language comfort zone.
                - Explore an Environment: An assignment suggested (I need to go through the list to recall who made it) has participants try out an alternative desktop environment and/or window manager. Learners participating in this assignment would make regular blog posts documenting their experience with a particular DE.
                - VTLUUG/VTCSEC: There were some issues with the attendance implementation at VTLUUG (in particular) and VTCSEC meetings that frustrated a lot of people and made my life a little more difficult. In addition, an attendance count isn’t really a good metric for the success of this assignment since the purpose isn’t simply to sit in a room for an hour, but to engage with a larger community. Next semester credit will be counted towards the VTLUUG/VTCSEC assignment for blog posts containing targeted discussion and thoughts of the specific topics covered at each meeting.</p>
            
            <h1 id="assignments">Assignments</h1>
            
            <p>I noticed several people commented that the Inventory Management assignment was about the time when python and the motivation behind assignments started to “click”. I don’t mind that it takes a few assignments in before connections start clicking, but I would like to try and provide more motivation up front about where each assignment is headed, so that earlier along there is at least a notion of “this is going somewhere”. So I’ve been penciling out a clear, focused progression of assignments that goes from basic text parsing up to something like Inventory Management. That project in particular I am also going to make into a group project so that there is some exposure to using git as a collaborative tool before the final project. It also easily breaks up into sub-modules:
              - Data Parser
              - Command Parser
              - Controller</p>
            
            <p>As the name implies the two parsers make use of text parsing concepts, while the controller is more of an exercise in logical program flow. I think with clear enough specs on what the internal data structures should look like, the three parts should be able to be written mostly independently and then combined into one project. I would also like to start C/C++ development earlier in the semester. I am going to try and restructure exercises and lecture slides so that C/C++ and Python assignments are interwoven throughout the semester. I hope that this will prevent the feeling that I got that the semester was split into two distinct phases, the “python” phase and “C++” phase. That way the content can follow a logical flow and touching on the merits of each language. A brief example of what I’m thinking about:
              - simple line parsing (one primitive type, e.g. double/int per line)
                - in python
                - in bash
                - in C++
              - processing command line arguments
                - in python
                - in bash
                - in C++
              - parsing text lines into an array structure
                - you get the picture
              - parsing text lines into a hierarchical structure (e.g. command parser)
                - probably drop bash for this case
              - manipulating lists
                - python list comprehension
                - C++ stl algorithms
              - Inventory Management (python)</p>
            
            <p>And I am toying with the idea creating a similar progression (overlapping mostly) that will cover fork/exec, basic IPC with pipe and lead to a simple shell. As I mentioned in the “Think about it” of the pipeline assignment, all were missing to create a basic shell program was a string parser that would parse something like “generator | consumer” into an array. Along those lines, I may adjust example code in the “Make a Makefile” assignment to use flex/bison to generate a simple command parser instead of an arithmetic parser. As those of you familiar with bash are aware, as the complexity of the algorithms and data structures we work with increase, at some point bash will become overly cumbersome. At this point, it will be relegated to the task of writing unit tests of sorts for each assignment (Thanks to <a href="http://unixramblingz.blogspot.com/">George</a> for <a href="https://github.com/dyreshark/IntroUNIX/tree/master/MakeYourOwnAssignment">the suggested assignment</a>.) This will make bash a more integral part of the course material, there was a notable lack of bash this past semester, which I regret.
            Classroom Time
            ==============</p>
            
            <p>I’ve been doing a lot of thinking about how to use the classroom time effectively in a way that makes everyone want to come. I think it’s really important that everyone shows up regularly, not just those that feel they need some extra guidance, but also those who have been programming in a *nix environment for 10 years. It’s really important because both the novice and expert can learn a lot from each other if they’re in the same room. It also makes my job easier. There are 60 people enrolled in the class in the Spring: it will be nearly impossible for me to check with everyone individually every time there is a typo in an entered command. Getting a second set of eyes looking at everyone’s commands and code will help people avoid extended debugging sessions and make people more aware of common typos and bugs. To that end I would like to do more collaborative discussions in the classroom, and less of me talking. Regarding assignments, I’d like them due and committed to a network accessible git repo at the beginning of class. Then, in class people will pair up, fork each others’ assignment, review, make edits, and initiate a pull request so that the original author can merge in any bug fixes. The grade for the assignment will be determined by a combination of the functionality of the original commit <strong>and</strong> the merged changes. This probably won’t take place after every assignment, but at least a view of them. Depending on how efficient we become at fork/review/merge, I’d like to have more discussions like the one we had about the Process Object assignment. I will try to come up with 3 or 4 “make you think” type questions for each assignment and then in class break up into groups, each discussing one question in depth, then come together as a full class and share the response each group had.
            Reflection
            ==========</p>
            
            <p>I think this post turned into more of a “What I plan to do next semester” more than the reflection I had intended. Because it’s probably already too long I’ll try and come to a close. The first semester I taught this course I pretty much followed the supplied lecture slides and exercises that were given to me. The second semester suffered from “all this stuff should be changed but I don’t have any rhyme or reason to it” syndrome (not unlike second system syndrome that Raymond talks about with regard to Multix). The next couple semesters, ending on the most recent, I have been tweaking and polishing and streamlining. There were still some bumps this past semester that I would like to eliminate (issues with VTLUUG attendance, problems submitting the midterm, lack of clarity on some of the assignments, much too long a delay on returning some of the graded assignments, to name a few), but I’m optimistic that the next revision will address many of them and hopefully provide a smoother and more enjoyable experience for all. Remind me to write another post about my vision for the class :) *and now I’m 10 hours in… only 4 more to go!</p>
          </article>
        </div>
        <div class='post'>
          <h1>
            <a href="/2012/12/211/">Re: the little things of ubuntu</a>
          </h1>
          <aside>Posted at: December 12, 2012</aside>
          <article>
            <p>In <a href="https://blogs.lt.vt.edu/thomaswy/2012/12/12/the-little-things-of-ubuntu/">a recent post</a><a href="https://blogs.lt.vt.edu/thomaswy/">thomaswy</a> mentioned some things he liked about the CLI in Ubuntu (Linux in general, running bash in any distribution should yield an extremely consistent experience) and some things he disliked about the GUI. He’s not alone, just do a quick google search for “what I hate about Ubuntu Unity”.  Luckily, there are numerous ways to resolve this.  If you read the “Futures” chapter and other bits about the X-windows system in The Art of Unix Programming you learned that to remain consistent with the Unix design philosophy the designers of X created a clear separation between policy and mechanism.  A result of this is several graphical toolkits available to developers who want to create a GUI, and a result of <em>this</em> is many different GUI environments.  Unity is but one of them and just because it comes packaged with Ubuntu doesn’t mean that’s all Ubuntu can use.  If you aren’t in love with Unity, consider some of the alternatives: <a href="http://www.makeuseof.com/tag/5-alternatives-unity-ubuntu-users-linux/">Alternatives to Unity</a> and because it didn’t make it onto the previous list: <a href="http://www.ubuntugeek.com/how-to-install-cinnamon-1-4-in-ubuntu-12-0411-10.html">Cinnamon</a> And that is but a small sampling of the graphical environments available for Linux.  A more complete list quickly becomes overwhelming <a href="http://www.linuxlinks.com/article/20081209153125602/WindowManagers.html">21 of the Best Free Linux Window Managers</a> and that still doesn’t include the one I use, <a href="http://i3wm.org/">i3</a>. It’s easy to see why Ubuntu, a distribution aimed at the casual user, would opt not to emphasize the amount of choices you have when it comes to picking a graphical environment! And then many of the environments are further configured through themes and settings to control the look and feel and behavior for events like “click on a minimized window”.  Yes, you can easily spend a day or more finding and configuring the “perfect” desktop.  But that’s what makes Linux fun ;-)</p>
          </article>
        </div>
        <div class='post'>
          <h1>
            <a href="/2012/12/structure-language-and-art/">Structure, Language and Art</a>
          </h1>
          <aside>Posted at: December 7, 2012</aside>
          <article>
            <p>In <a href="https://blogs.lt.vt.edu/tylera5/2012/12/07/poems/">a recent post</a><a href="https://blogs.lt.vt.edu/tylera5/">tylera5</a> commented that the last time he wrote poetry was in high school, and wasn’t expecting to have to write a poem for a programming course. I got the idea for a poetry assignment from a friend of mine who teaches a biological science course. She found that the challenge of condensing a technical topic into a 17 syllable Haiku really forces one to think critically about the subject and filter through all the information to shake out the key concept. And poems about tech topics are just fun to read! I think the benefit is even increased for a programming course. As tylera5 mentioned, both poems had a structure, and he had to think a bit about how to put his thoughts into the structure dictated by the poetry form, whether it be the 5/7/5 syllable structure of a <a href="http://en.wikipedia.org/wiki/Haiku_in_English">Haiku</a>, or the AABBA rhyming scheme of a <a href="http://en.wikipedia.org/wiki/Limerick_(poetry)">limerick</a>. Poetry is the expression of ideas and thoughts through structured language (and the structure can play a larger or lesser roll depending on the poet, and type of poetry). Programming also is the expression of ideas and thoughts through structured language. The domain of ideas is often more restricted (though not necessarily, <a href="http://www.slate.com/articles/technology/books/2012/11/computer_programming_10_print_chr_205_5_rnd_1_goto_10_from_mit_press_reviewed.html">this article and book</a> could be the subject of a full post in its own right) and adherence to structure is more strict, but there is an art to both forms of expression. Are there artistic and expressive tools in other STEM topics as well?</p>
          </article>
        </div>
        <div class='post'>
          <h1>
            <a href="/2012/12/the-tides-of-change/">The Tides of Change?</a>
          </h1>
          <aside>Posted at: December 3, 2012</aside>
          <article>
            <p>As Linus Torvalds has mentioned in <a href="http://www.youtube.com/results?search_query=Linus+Torvalds+interview&amp;oq=Linus+Torvalds+interview">several video interviews</a>, probably the main reason Linux has been lagging behind in the desktop market is that it doesn’t come pre-installed on desktop hardware, and the average computer user just isn’t going to put forth the effort to install a different operating system and configure it* than came with their new machine. Recently Dell caused <a href="http://www.zdnet.com/dell-xps-13-laptop-the-ubuntu-developer-edition-arrives-7000008059/">a bit of excitement</a> with their release of an Ubuntu addition of their “<a href="http://www.dell.com/us/soho/p/xps-13-linux/pd.aspx">XPS 13: The Ubuntu developers</a>” edition laptop.  To be fair, this is not the first machine that Dell has offered with Linux pre-installed, but it does seem to be the first that they’ve tried pushing to the mainstream (or in this case, developer) community (in the past you really had to make an effort to find the Ubuntu option on their ordering form).  Dell is also <a href="http://linuxpreloaded.com/">not the only desktop distributor</a> to offer systems with Linux pre-loaded (indeed, many of the others exclusively offer Linux machines), but it is probably the brand with the most name recognition to the general audience.  Could this be the beginning of the end of the Microsoft monopoly on the desktop OS market?  I am optimistic! *Be wary of the blog posts and forum comments that recount stories of installing Linux and being frustrated with the difficulty of getting all the necessary drivers for their hardware and using that as an argument that the OS wasn’t “ready” for prime time.  If you have ever installed Windows on a fresh new machine you will be well aware that it can be just as frustrating.  Windows doesn’t “just work” on the machines you buy because it is a superior OS (it isn’t), it works because the system distributors like Dell take the time to make sure that the necessary drivers for the particular hardware in the machine are all included.</p>
          </article>
        </div>
        <div class='post'>
          <h1>
            <a href="/2012/11/re-large-scale-makefiles/">Re: large scale makefiles</a>
          </h1>
          <aside>Posted at: November 25, 2012</aside>
          <article>
            <p>In a <a href="https://blogs.lt.vt.edu/thomaswy/2012/11/21/large-scale-makefiles/">recent post</a> <a href="https://blogs.lt.vt.edu/ece2524/author/thomaswy/">thomaswy</a> asked about maintaining makefiles for larger projects.  It is certainly true that manually updating lists of dependencies for many (hundreds… thousands even, the Linux kernel is comprised of some 22,000 source files) can become tedious.  Luckily there are tools that will generate Makefiles for you, though really their motivation is to automate the build process on a wide variety of machines and platforms.  If you’ve used Qt for development you have probably been using the ‘qmake’ command.  This is generate a ‘Makefile’ that is then read with a subsequent call to ‘make’.  For more general projects GNU provides Autoconf and Automake.  Along with a couple other programs these are referred to as the <a href="http://www.gnu.org/savannah-checkouts/gnu/automake/manual/html_node/Autotools-Introduction.html">GNU Autotools</a>.  If you ever need to install a piece of GNU software from source (if a package isn’t available for your distribution, for instance) chances are it will use Autotools and you will build it with two commands: [code light=”true” lang=”bash”] $ ./configure $ make [/code] The first command will generate the Makefile that is then used when you run <code>make</code>.  In the process of generating the Makefile, <code>configure</code> will check your system for necessary libraries and tools and notify you if something needed is missing.  This is also where you would specify optional build parameters.  To get a list of options run [code light=”true” lang=”bash”] $ ./configure –help [/code] If you decide you do want to make your project available to the open source community, it’s a good idea to set up the build process using GNU Autotools since folks will be expecting it. Another option is <a href="http://www.cmake.org">cmake</a>, which provides similar functionality to GNU Autotools and in addition has the capability to generate project files for a number of IDEs. A quick google search will turn up several commentaries on the merits of the two build systems (and probably several others). If you do find yourself writing several Makefiles for larger projects (and even if you don’t), be sure to familiarize yourself with the issues raised in the now well-known paper <a href="http://miller.emu.id.au/pmiller/books/rmch/">Recursive Make Considered Harmful</a> by Peter Miller.</p>
          </article>
        </div>
        <div class='post'>
          <h1>
            <a href="/2012/10/response-to-class-material-reposted/">Response to "Class Material – reposted"</a>
          </h1>
          <aside>Posted at: October 20, 2012</aside>
          <article>
            <p>In his post titled <a href="https://blogs.lt.vt.edu/zickece2524/2012/10/15/class-material-reposted/">Class Material – reposted</a>, <a href="https://blogs.lt.vt.edu/ece2524/author/zickbe/">zickbe</a> asked a very good question about the content of ECE2524.  This is a question that has come up at least once every semester, to paraphrase it is “Since there are modern GUI tools for Linux now, why are we learning all these old command line tools?” The example given in the post was a simple task of replacing all periods ‘.’ with commas ‘,’ in some text input.  Indeed, many graphical editors do have search and replace functionality that make this particular task quite easy.  So what’s the point of learning to do it from the command line? There are two answers to this question, each from a different perspective.</p>
            
            <h2 id="you-as-the-user">You as the User</h2>
            
            <p>The first is probably the perspective you are all thinking about right now: you as a user of a general-purpose operating system, editing files, writing code, surfing the web, etc.  As we have seen already, Unix has a strong tradition as a platform for text manipulation (remember, its first use was as an OS to run a word processing system for the AT&amp;T Bell Labs patent department).  When we store our data in plain text we have a large collection of powerful tools to manipulate and process that data. Of course, when learning new concepts we start with simple examples.  One of the simplest ways we can manipulate text is with a literal substitution, for example “replace all occurrences of the word ‘cat’ with ‘dog’ “, or “replace all occurrences of ‘.’ with ‘,’ “.  Literal substitutions are used often enough that many graphical tools have implemented the feature into the interface.  Let’s say we have a file myfile.txt and we want to change all occurrences of ‘dog’ to ‘cat’, we could either use the terminal: [code light=”true” language=”bash”] sed -i ‘s/dog/cat/g’ myfile.txt [/code] Or we could open myfile.txt in our favorite text editor, choose the menu option for “search and replace”, enter “dog” and “cat” in the appropriate field, click “ok” and we’re done.  For this simple case it seems like it’s hardly worth the brain-space to remember how to use sed.  Let’s kick it up a notch though.  When writing software applications we often have many files associated with one project.  What if we wanted to replace ‘dog’ with ‘cat’ across several files?  Using the GUI we would open each file in succession, click the menu that contained “search and replace” fill in our search and replace words, hit ‘ok’ and then repeat for the remaining files.  This is probably doable for a few files.  What about 100?  1000? [code light=”true” language=”bash”] find project/ -name <em>.txt -exec sed -i ‘s/dog/cat/g’ ‘{}’ + [/code] or [code light=”true” language=”bash”] find project/ -name *.txt | xargs sed -i ‘s/dog/cat/g’ [/code] The nice thing about this is that the amount of effort we put in is the same no matter how many files we want to process, whether it be 3, 100, 1000 or more.  Try doing 100 text substitutions in a GUI and you’re asking for a repetitive stress injury! “Ok”, you’re saying to yourself “but how often am I working with hundreds of files at once? I usually just have one or two files I want to modify, it’s not too bad to navigate the GUI menu a few times to do text substitution.”  Let’s think of some more examples of text manipulation you might want to do. In my previous post I described the process I went through to compile a list of links to last semester’s projects. At one point I wanted to prepend each line with a ‘-‘ character to generate a list in Markdown syntax.  I could have just manually added the character to each line, there were only 19, after all, but instead I used a sed command [code light=”true” language=”bash”] sed -r ‘s/^(.</em>)$/- \1/g’ [/code] It didn’t really save me many keystrokes in this case, but it easily fit into the automated workflow I had set up to convert the list of urls to a nice HTML format suitable for posting on the blog. It’s also a task that would have become quite tedious to do by hand if there were more than the 20 or so items that I had. And if I wanted to do somethling a bit more complex like “prepend only the lines containing a url with ‘-‘ but leave all others unchanged” [code light=”true” language=”bash”] sed -r ‘s|^(.<em>https?://.</em>)|- \1|g’ [/code] Now I can selectively convert lines to a Markdown style list. This is much quicker for even medium sized files than scanning each line by eye to find urls, and then adding a ‘-‘. Can your GUI do that? And of course, if I had a few, or a few hundred files that I wanted to process like this, I could use the same <code>find ... -exec</code> or <code>find ... | xargs ... </code> idiom I used above. Another quick example: You are probably familiar with the two main styles of naming functions with multiple words: CamelCase and underscore_case [code light=”true” language=”python”] def myHelloFunction: pass def my_hello_function: pass [/code] Which style you use is largely a matter of preference, although sometimes when working on collaborative projects the project will define a particular style that you must adhere to. Let’s say you’ve been using one style for a few projects and then decide you want to switch (or you get a bunch of code from a friend who was using a different style, or… ) [code light=”true” language=”bash”] sed -r ‘s/([A-Z])/_\l\1/g’ [/code] Will convert CamelCase to camel_case. Doing the same automatic formatting in a GUI of your choice is left as an exercise for the reader.  A quick google search will turn up a sed command to do the reverse transformation. The take-away from all of this is that while the examples we use in class may be simple enough that it just so happens that a GUI editor has implemented similar functionality the tools themselves are much more powerful. GUIs are great in that they make it really easy to do the things that the GUI designers planned for. However, they make it difficult or impossible to do things that the designers didn’t plan for.  In the case where you want to perform a text manipulation on a large number of files, or a complex manipulation on one or more files, the command line tools provide a solution where the graphical tools do not.
            You as the Developer
            ——————–</p>
            
            <p>But you’re not just any user are you? You are getting a degree in Computer Systems Engineering, and even if you plan to focus on hardware it is a guarantee that you will be writing software at some point (probably many points).  You may even write some software that needs to do text manipulation.  Perhaps a preprocessor for a compiler, or even your own text editor.  What if you want to build in some functionality to allow the end-user to do some text manipulation. Maybe a simple text substitution, or perhaps you’re writing an IDE and want to provide a menu option to automatically convert CamelCase to camel_case across a set of project files.  How would you implement this?  For these examples it probably makes sense to use the regular expression library of whichever language you are programming in, but even in that case, the expressions themselves will be the same as in the sed example.  In some cases you may actually want to spawn a child process running one of the sed commands from above directly (maybe you want to run a complex text manipulation on a large number of files that a user selects with a GUI and let the manipulation run in the background while the GUI is free to take additional requests from the user).
            Summary
            ——-</p>
            
            <p>As you are working with the command line and working through the examples for this class remember to keep in mind the flexibility of the commands you are learning.  In many cases the examples will be so simple that the same functionality has been implemented in any of the popular graphical tools, but the command line version provides much more control and flexibility, as I hope these few examples have demonstrated.  Can you think of any other examples that could be done using command-line text manipulation tools but would be impossible in a general purpose graphical environment? As I mentioned before, this question comes up every semester.  How could the material in the class be modified to make the power of the tools we learn more apparent?  Should more complex examples be included at the possible expense of clarity? More examples?  Was the explanation I gave here convincing?  If not, please explain why in the comments and I’ll do my best to revise!</p>
          </article>
        </div>
        <div class='post'>
          <h1>
            <a href="/2012/10/list-of-projects-past/">List of Projects Past</a>
          </h1>
          <aside>Posted at: October 12, 2012</aside>
          <article>
            <p>I wanted to generate a list of Unix projects from last semester to provide a reference for what has been done before. The first complete list I found was in the forum of last semester’s Scholar site. There wasn’t a “download” option, and given the formatting I predicted that I’d spend more time writing a program to parse the raw HTML file and properly match up titles to urls than I’d save by just doing an old fashioned copy and paste operation for the 19 projects. So that’s what I did, and ended up with a file one title/url per line formatted like this: [code light=”true”] Snake Game https://github.com/ccwertz7/2524snake Go, Dog, Go https://github.com/rokthewok/ECE2524-Final-Project … [/code] Just white space separating the title and the url. I wanted to generate a nicely formatted list of links to each project and also filter out any urls that were no longer valid, so I wrote a short python script that read in lines of test, split them at the ‘http’ of a possible url treating everythign to the left of the split as the title and then used the urllib module to check for a 200 status before printing out a markdown formated line: [code light=”true”] <a href="https://github.com/ccwertz7/2524snake">Snake Game</a> <a href="https://github.com/rokthewok/ECE2524-Final-Project">Go, Dog, Go</a> [/code] I have uploaded the source for <a href="https://github.com/hazybluedot/ece2524/blob/master/examples/url_200filter.py">this program</a> to the <a href="https://github.com/hazybluedot/ece2524/tree/master/examples">examples</a> directory in my <a href="https://github.com/hazybluedot/ece2524">ece2524</a> repository on github.  After checking the output of my program I decided that I’d like to create a bulleted list by preceding each line with a ‘- ‘ (this is standard Markdown syntax).  Rather than change my python script, which is already on the verge of being too specific to be useful for much else, I just piped the output through a simple sed command to tack on the dash: [code light=”true” language=”bash”] url_200filter.py  Spring2012ProjectList.html [/code] To generate the HTML code that I then pasted here:</p>
            
            <ul>
              <li><a href="https://github.com/ccwertz7/2524snake">Snake Game</a></li>
              <li><a href="https://github.com/rokthewok/ECE2524-Final-Project">Go, Dog, Go</a></li>
              <li><a href="https://github.com/rc2524/Battleship-game">Battleship Game</a></li>
              <li><a href="https://github.com/lubbs65/Catan">Settlers of Catan</a></li>
              <li><a href="https://github.com/rogpog13/ECE2524_LostPyramidOfUnix">Pyramid of Unix</a></li>
              <li><a href="https://github.com/cabotzj/guessing_game">Guessing Game</a></li>
              <li><a href="https://github.com/tavispa/Timer_Application">Timer Application</a></li>
              <li><a href="https://github.com/cfol103/Terminal_Game">Dodge the ASCII Characters Game</a></li>
              <li><a href="https://github.com/gomezfx/ECE2524_Millionaire">Millionaire Game</a></li>
              <li><a href="https://github.com/cfol103/Terminal_Game">Terminal Game</a></li>
              <li><a href="https://github.com/alexsupp/CheckersGame">Checkers Game</a></li>
              <li><a href="https://github.com/gecock14/UnixFinalProject">Text Adventure Game</a></li>
              <li><a href="https://github.com/lnr0626/Monopoly">Monopoly</a></li>
              <li><a href="https://github.com/JCAMP17/Hangman-Final-Project">Hangman</a></li>
              <li><a href="https://github.com/patrickto2/ECECalculator">ECECalculator</a></li>
              <li><a href="https://github.com/hessionb/ece2524">Class Catcher</a></li>
              <li><a href="https://github.com/MattyBo5/Game-of-Life">Conway’s Game of Life</a></li>
              <li><a href="https://github.com/crimsondynamo329/Tic-Tac-Toe">Tic Tac Toe</a></li>
              <li><a href="https://github.com/0x5654/ece2524">Leaderboards Hub</a></li>
            </ul>
            
            <p>While you are thinking about project ideas keep in mind that the goal of the project is to apply and demonstrate understanding of the Unix design philosophy.  A project doesn’t need to be terribly complex to show this, but if you have a complex idea that you would really like to explore it may be sufficient to just implement a piece of it for this project.  I look forward to hearing about your ideas and discussing some details next week!</p>
          </article>
        </div>
        <div class='post'>
          <h1>
            <a href="/2012/10/response-to-advanced-python-exercises/">Response to "Advanced Python exercises"</a>
          </h1>
          <aside>Posted at: October 1, 2012</aside>
          <article>
            <p>Recently Matt brought up some good points in his post <a href="https://blogs.lt.vt.edu/mwhitema/2012/10/01/advanced-python-exercises/">Advanced Python exercises</a>.  First, the more easily addressed one: To break up a Python program into multiple functions, just store related functions in a separate <code>.py</code> file, then in the main source use import For example, if you have a file named <code>hello.py</code> that contains [code light=”true” language=”python”] def greeting(string): return “Hello, {}”.format(string) [/code] Then in your main source file (located in the same directory), you can import <code>hello.py</code> and all the functions will be available from the <code>hello</code> namespace: [code light=”true” language=”python”] import hello print hello.greeting(“world”) [/code] Easy as .py! (sorry) Also in the post Matt talked about Python’s use of “try” and “except” as a means of flow control, as an example: [code light=”true” language=”python”] try: mynumber = float(line) except ValueError as e: sys.stderr.write(“We have a problem: {}”.format(e)) else: print “We have the number {}”.format(mynumber) [/code] He said “if complex return types are needed such that you’re throwing exceptions to communicate logic information rather than true fatal errors, your function needs to be redesigned.” which I agree with. But I disagree that Python itself relies on this technique, or encourages it, though of course individual developers may miss-use it. Like the programs they are a part of functions should be written to do one thing and one thing well. In the preceding example the function float converts its argument to a floating point value. The name of the function makes it very clear what it does, and it does its job well. If it <strong>can’t</strong> do it’s job, then it raises a ValueError exception.  All other built in and library functions I’ve seen work the same way.  Think about the alternative without exceptions, for example, C: [code light=”true” language=”c”] double n = atof(line); printf ( “We have the number %f\n” , n); //Except if n == 0 it could be because there was no valid numeric expression in line [/code] According to the documentation for atof:</p>
            
            <pre><code> On success, the function returns the converted floating point number as a double value. If no valid conversion could be performed, the function returns zero (0.0). There is no standard specification on what happens when the converted value would be out of the range of representable values by a double. See [strtod](http://www.cplusplus.com/strtod) for a more robust cross-platform alternative when this is a possibility.&#x000A;    </code></pre>
            <p>This is less than ideal. If we wanted to check if an input even contained a valid numeric string (which we usually would) we’d have to work harder. The strtod alternative provides a means to do that, but we’d still have to do an explicit check after calling the function.  Other C-style functions use a return code to indicate success or failure.  It is also extremely easy to forget to check return codes, in which case the problem may only manifest itself in a crash later on, or worse, not at all, but instead just produce bad output.  These types of problems are very hard to track down and debug.  Using exceptions the program crashes precisely where the problem occurred unless the programmer handles that particular exception. So to summarize: Each of your functions should have a well-defined job.  They should do only one job and do it well.  If they can’t do their job because of improper input, then they should raise an appropriate exception.  I think following that idiom results in cleaner, easier to debug code.  You could certainly still return complex data types where appropriate, but trying to incorporate success/failure information in a return type will often lead to difficult to debug errors when the programmer forgets to check the return status!</p>
          </article>
        </div>
        <div class='post'>
          <h1>
            <a href="/2012/09/but-what-does-it-all-mean/">But What Does It All Mean?</a>
          </h1>
          <aside>Posted at: September 27, 2012</aside>
          <article>
            <p>We are at that point in the semester where we are all feeling a bit overwhelmed.  We’re past the introductory material, covered a lot of new concepts and ideas, there’s the threat of a midterm on the horizon, and to make matters worse the same thing is happening in every other class as well. It is not surprising that this is also the part of the semester in which I get questions like “why are we learning this?”, “how do these assignments teach me about Unix?”, or “we’ve covered a lot of commands, a lot of new ideas, done several assignments, what should I focus on?” or “how does it all fit together?” These are good questions to ask, and a good exercise to answer, both for me, so that I can better shape the course to meet its goals, and for the participants in the course to solidify the connections between different material and concepts.  I will attempt to start that process by providing my own thoughts addressing these questions: Learning Unix is as much (if not more) about learning a different way of thinking and problem solving with a computer as it is about learning how to use the terminal and acclimating yourself to the different GUI environments.  And while we’re on the topic of user interfaces, there are several.</p>
            
            <h2 id="rule-of-diversitydistrust-all-claims-for-one-true-wayhttpcatborgesrwritingstaouphtmlch01s06htmlid2879078"><a href="http://catb.org/esr/writings/taoup/html/ch01s06.html#id2879078">Rule of Diversity: Distrust all claims for “one true way”</a></h2>
            
            <table>
              <tbody>
                <tr>
                  <td>Unlike Windows or OS X which provides only a single graphical environment to its users and a single graphical toolkit to its developers, Unix systems have multiple options for both environments (e.g. Ubuntu’s Unity, GNOME Shell, KDE) and toolkits (GTK, Qt are the most common).  This confusing jumble isn’t just to make it needlessly annoying for users, in fact it is the result of one of Unixes core philosophies: the users has a better idea of what he/she wants to do than the programmer writing an application.  As a result, many decisions are pushed closer to the user level.  This is sometimes listed as a downside to Unix/Linux, since it increases the perceived complexity of the system to the user, but luckily many distributions have been set up to select a sensible default choice for most people who would rather jump right into using their computer, rather than configuring it.  Ubuntu, with its Unity interface, is a good example of this. But it’s empowering to be aware that you aren’t stuck with Unity, you can install and use any of the other graphical environments as well, such as GNOME, KDE, LXDE, and more. Moving on, but keeping The Rule of Diversity in mind, let’s revisit the examples we looked at in class.  The first was related to the homework in which we were asked to read in lines in a white-space delimited record format containing fields for “First Name”, “Last Name”, “Amount Owed”, and “Phone Number”.  A short example of such a file is [code light=”true”] Bill Bradley 25.20 Blacksburg 951-1001 Charles Cassidy 14.52 Radford 261-1002 David Dell 35.00 Blacksburg 231-1003 [/code] We were then asked to write a program that would print out information for people in ‘Blacksburg’ in the order of “Phone Number”, “Last Name”, “First Name”, “Amount Owed”. A straight forward way to solve this using Python is with the following code snippet [code light=”true” language=”python”] for line in f: fields = line.split() if fields[3] == ‘Blacksburg’: record = [fields[4], fields[1], fields[0], fields[2]] print ‘, ‘.join(record) [/code] In class we looked at an alternative solution using list comprehension: [code light=”true” language=”python”] for fields in (r for r in imap(str.split, f) if r[3] == ‘Blacksburg’): print ‘, ‘.join(fields[i] for i in [4,1,0,2]) [/code] Both of these examples can be found on <a href="https://github.com/hazybluedot/ece2524/tree/master/examples">github</a>.  They both do the same thing.   The first takes 5 lines, the second 2.  I made use of a few convenience features to make this happen, the first is the <a href="http://docs.python.org/library/itertools.html#itertools.imap">imap</a> function, the iterator version of the <a href="http://docs.python.org/library/functions.html#map">map</a> function.  The map function is common under many functional programming languages and implements a common task of applying a function (in this case str.split) to every element in a list (in this case f, the file object). This is an extremely common task in programming, but there is no analog in C but luckily the STL Algorithms library gives us <a href="http://www.cplusplus.com/reference/algorithm/transform/">std::transform</a> for C+, though the syntax isn’t nearly as clean as Python’s. So the big question is “If I’ve been implementing this idiom all along, without ‘map’, why change now?”  The answer is that implementing it without map will be guaranteed to use more lines of code, with which we know there is a statistically higher chance of making a mistake.  In addition, the implementation would look a lot like any of the other loops that you have written in the same program and you will find yourself pausing at it to ask yourself “What am I trying to do here?”.  Once you learn the concept of ‘map’, using it is much more concise.  Looking at the call to “map” you know exactly what is going on without having to mentally process a “for” or “while” loop.  This idea is generalized to the concept of <a href="http://en.wikipedia.org/wiki/List_comprehension">list comprehension</a>, which is what we’re doing with the rest of that line.  Working with a list of things is really common in programming, and one of the common things we do with lists is to generate new lists that are some filtered and transformed version of the original.  List comprehension provides a cleaner syntax (similar to the set comprehension that you may be familiar with in mathematics) to transforming lists than the traditional “for” or “while” loop would yield.  And more importantly, once you get familiar with the syntax, it lets you more quickly recognize what is going on.  For example, let’s look at two ways of computing a list of the <a href="http://en.wikipedia.org/wiki/Pythagorean_triples">Pythagorean triples</a> for values 1 through 10 [code light=”true” language=”python”] triples1 = [] for x in xrange(1,11): for y in xrange(1,11): for z in xrange(1,11): if x<strong>2 + y</strong>2 == z<strong>2: triples1.append((x,y,z)) print triples1 [/code] and now, using list comprehension: [code light=”true” language=”python”] triples2 = [ (x,y,z) for x in xrange(1,11) for y in xrange(1,11) for z in xrange(1,11) if x</strong>2 + y<strong>2 == z</strong>2 ] print triples2 [/code] I’ve broken the second example across several lines so that it will all fit on the screen, but it could be left on a single line (<a href="https://github.com/hazybluedot/ece2524/blob/master/examples/pythagorean_triples.py">see the full, working example</a>) and still be just as readable.  Right off the bat we can look at the second version and tell that <code>triples2</code> will be a list of tuples containing three values (x,y,z).  We had to work our way down to five levels of nested blocks to figure that out in the first example.  And while you may not realize it because you’re so used to doing it, our brains have a much more difficult time following what is going on in a nested loop, it implies a specific hierarchy that is misleading for this problem. Let’s shift gears just a bit and look at some of the commands I ran at the end of class.  I first wanted to count all the lines of code in all of the *.py files in my current directory: [code light=”true” language=”bash”] cat *.py</td>
                  <td>wc -l [/code] Then I wanted to revise that and filter out any blank lines: [code light=”true” language=”bash”] cat *.py</td>
                  <td>sed ‘/^$/d’</td>
                  <td>wc -l [/code] And let’s also filter out any lines that only contain a comment [code light=”true” language=”bash”] cat *.py</td>
                  <td>sed ‘/^$/d’</td>
                  <td>sec ‘/^#.*$/d’</td>
                  <td>wc -l [/code] (note, we could have combined the two <code>sed</code> commands into one, I separated them to emphasize the idea of using a pipeline to filter data) Next I wanted to know what modules I was importing. [code light=”true” language=”bash”] cat *.py</td>
                  <td>grep ‘^import’ [/code] Say I wanted to isolate just the names, I could use the <code>cut</code> command [code light=”true” language=”bash”] cat *.py</td>
                  <td>grep ‘^import’</td>
                  <td>cut -d ‘ ‘ -f 2 [/code] If you didn’t know about the <code>cut</code> command you could use sed’s <code>s</code> command to do a substitution using regular expressions. I will leave the implementation of this as an exercise for the reader. We notice that there are few duplicates, let’s only print out unique names [code light=”true” language=”bash”] cat *.py</td>
                  <td>grep ‘^import’</td>
                  <td>cut -d ‘ ‘ -f 2</td>
                  <td>sort</td>
                  <td>uniq [/code] Exercise for the reader: why is the <code>sort</code> necessary? And finally, let’s count the number of uniq modules I’m using [code light=”true” language=”bash”] cat *.py</td>
                  <td>grep ‘^import’</td>
                  <td>cut -d ‘ ‘ -f 2</td>
                  <td>sort</td>
                  <td>uniq</td>
                  <td>wc -l [/code] I could have just shown you the final command and said “this prints the number of modules I’m using” but I wanted to demonstrate the thought process to get there. We started with just a two command pipeline, and then started building up the command one piece at a time. This is a great example of another core Unix philosophy: write simple programs that do one thing and one thing well, and write them with a consistent interface so that they can easy be used together. Now I admit, counting the number of modules uses this way required us to start up 6 processes. Luckily process creation on Unix systems is relatively cheap by design. This had the intended consequence of creating an operating environment in which it made sense to build up complex commands from simpler ones and thereby encouraged the design of simple programs that do one thing and one thing well. We could write a much more efficient program to do this task in C or another compiled language, but the point is, we didn’t have to. As you get more familiar with the simple commands you’ll find that there are many tasks like this you want to do that occur too infrequently for writing a dedicated program, but can be pieced together quickly with a pipeline. So what the heck do these to different topics: list comprehension and command pipelines, have in common?  And why are we using Python at all? Well, Unix’s strength is that it provides a huge wealth of excellent tools and supports a large number of programming languages.  It does everything an operating system can do to allow you, the developer, to pick the best tool for the job.  As we mentioned before, when we’re developing a program the “best tool” usually means the one that will allow us to solve the problem in the fewest lines possible.  Python’s syntax is much cleaner than that of C or C++, and its support of convenience features like list comprehension allow us to implement algorithms that might normally take several loops in a less expressive language in one, easy to understand line. This has been a rather long post, I hope you’re still with me.  To summarize, don’t worry too much about memorizing every single command right away, that will come naturally as you use them more often (and a refresher is always just a quick call to <code>man</code>).  Instead shift your thinking to a higher level of abstraction and always ask yourself “what tools do I have available to solve this problem” and try to pick the “best” one, whatever “best” means in the context you are in.  Unix/Linux puts you, the user and you, the developer in the drivers seat, it provides you with a wealth of knobs and buttons to press, but does little to tell you which ones it thinks you <em>should</em> press.  This can be intimidating, especially coming from a Windows or OS X environment which tends to make most of the choices for the user.  That’s ok, and to be expected.  With practice, you will learn to appreciate your newly discovered flexibility and will start having fun! I want to know what you think! Share your thoughts on what we’ve gone over  in class, the assignments we’ve done, and the reading we’ve discussed.  How do you see it all fitting together?</td>
                </tr>
              </tbody>
            </table>
          </article>
        </div>
        <div class='post'>
          <h1>
            <a href="/2012/09/mary-poppins/">Mary Poppins</a>
          </h1>
          <aside>Posted at: September 7, 2012</aside>
          <article>
            <p>I just finished up Ruby - Day 3 from <a href="http://pragprog.com/book/btlang/seven-languages-in-seven-weeks">Seven Languages in Seven Weeks</a>.  I can’t say I fully grok everything that I’ve done, but Ruby seemed fairly straight forward and in many ways similar to Python (though I have noticed Rubyites tend to be able to on a moments notice generate a long list of why it’s better than Python). I had originally wanted to learn Ruby because I’ve been trying to re-launch my website and blog using <a href="http://nanoc.stoneship.org/">nanoc</a>, which is written in Ruby.  While strictly speaking it isn’t necessary to understand Ruby to use nanoc, any type of customization will require writing and manipulating Ruby code, and knowing me, I’ll want to do some customization.  I feel I understand enough of the syntax and a bit of the power-features of the language to get by understanding the bits of nanoc that I might be customizing, but I definitely have a long way to go with a lot more experimenting before I could say I’m comfortable with the language, but I suppose that’s to be expected! Maybe it’s due to my very preliminary understanding of it, but I feel kind of let down by all the hype.  Perhaps it’s because it’s an OOP language, and so in many respects similar to Python, or even C++ in terms of how the code is structured, but I didn’t really get terribly excited about it as I was working with it.  I’m really looking forward to the other languages in the book and breaking away from OOP thinking.  From the descriptions, it sounds like each of them encourage a different type of thinking when writing code and designing a program.  Even though it’s last on the list, I I’m going to start the Haskell section next, mainly because I’ve already dabbled in it a bit, and I’d like to write up an assignment using a functional programming language, so I should probably learn enough of one to be able to actually write up a solution!</p>
          </article>
        </div>
        <div class='post'>
          <h1>
            <a href="/2012/09/rule-of-diversity-distrust-all-claims-for-one-true-way/">Rule of Diversity: Distrust all claims for “one true way”.</a>
          </h1>
          <aside>Posted at: September 2, 2012</aside>
          <article>
            <p>I’ve been programming simulations and algorithms in C++ for several years now, but it’s only been in the last year or so that I’ve really began to appreciate the advantages of diversifying ones language repertoire.  My conversion began after reading <a href="http://catb.org/esr/writings/taoup/html/">The Art of Unix Programming</a> by Eric Raymond last year while exploring new material for ECE2524.  In the book Raymond lays out a list of design rules making up the Unix philosophy and explains how following these rules has produced clean, powerful, maintainable code and been the reason why Unix has so easily evolved and adapted and flourished in the fast paced world of technology from it’s roots in 1969 running on under-powered hardware, even for the time. The <a href="http://catb.org/esr/writings/taoup/html/ch01s06.html#id2879078">Rule of Diversity</a> appears towards the end of the list, but is interesting in that I feel it is one of the few rules that few people, curriculums or corporations outside of the Unix community have yet to seriously embrace.  I hope that people with a Computer Science background can contribute their own view, but in my experience with the limited software design instruction in my Engineering curriculum, and talking to several other people, the focus has been strictly on Object Oriented Programming (<a href="http://en.wikipedia.org/wiki/Object_Oriented_Programming">OOP</a>), usually using Java or C++. As a result of this focus on OOP, programmers (including my past self) are encouraged to  adopt a programming paradigm that may work well for some problems, but not well for others.  I’ve learned from first hand experience that forcing an OOP framework on a problem that doesn’t really lend itself intuitively to the features of the framework (data encapsulation, inheritance) leads to an impossible-to-maintain mess consisting of many layers of brittle “glue” code and a spiting headache as soon as concurrent processing is thrown into the mix. Discovering the Rule of Diversity was refreshing to me for many reasons, as I tend to reject dogma of any kind, but hadn’t really been made aware of the alternatives when it came to programming.  This process lead to me learning <a href="www.python.org">Python</a>, which I now use to do the majority of my data visualization, and becoming interested in <a href="http://www.ruby-lang.org/">Ruby</a> for web development and <a href="http://www.haskell.org/">Haskell</a> to learn about functional programming and how I might employ it to more elegantly implement the mathematical algorithms that are a large part of my field of study (Control Systems). When a friend of mine recommended <a href="http://pragprog.com/book/btlang/seven-languages-in-seven-weeks">Seven Languages in Seven Weeks</a> by Bruce A. Tate I was intregued by the idea of learning 7 different programming languages, along with their strenghts, weaknesses, histories and accompanying programming philosophies.  When I found out that two of the languages covered were Ruby and Haskell I was sold. I have decided to work my way through the book over the next 7 weeks, and write about my experience with each language.  So far I really enjoy the structure of the book, the motivations of the author, and in particular his method of associating each language with a unique fictional character:</p>
            
            <ul>
              <li>
            <a href="http://www.imdb.com/character/ch0011238/">Mary Poppins</a> from <a href="http://www.imdb.com/title/tt0058331/">Mary Poppins</a>(1964) - (Ruby) because unlike other nannies of the time she “made the household more efficient by making it fun and coaxing every last bit of pasion from her charges.” And wasn’t afraid to use a little magic to accomplish her goals.</li>
              <li>
            <a href="http://www.imdb.com/character/ch0005859/">Ferris Bueller</a>  from <a href="http://www.imdb.com/title/tt0091042/">Ferris Bueller’s Day Off</a>(1986) - (Io) ”He might give you the ride of your life, wreck your dad’s car, or both.  Either way, you will not be bored.”</li>
              <li>
            <a href="http://www.imdb.com/character/ch0004559/">Raymond</a> from <a href="http://www.imdb.com/title/tt0095953/">Rain Man</a>(1988) - (Prolog) ”He’s a fountain of knowledge, if you can only frame your question in the right way.”</li>
              <li>
            <a href="http://www.imdb.com/character/ch0005544/">Edward Scissorhands</a>from <a href="http://www.imdb.com/title/tt0099487/">Edward Scissorhands</a> (1990) - (Scala) “He was often awkward, was sometimes amazing, but always had a unique expression.”</li>
              <li>
            <a href="http://www.imdb.com/character/ch0000745/">Agent Smith</a>from <a href="http://www.imdb.com/title/tt0133093/">The Matrix</a>(1999) - (Erlang) “You could call it efficient, even brutally so, but Erlang’s syntax lacks the beauty and simplicity of, say, a Ruby.”  ”Agent Smith … had an amazing ability to take any form and bend the rules of reality to be in many places at once. He was unavoidable.”</li>
              <li>
            <a href="http://www.imdb.com/character/ch0000015/">Yoda</a>from <a href="http://www.imdb.com/title/tt0080684/">Star Wars: Episode V - The Empire Strikes Back</a> (1980) - (Clojure) “His communication style is often inverted and hard to understand”, “he is old, with wisdom that has been honed by time … and tried under fire.”</li>
              <li>
            <a href="http://www.imdb.com/character/ch0001439/">Spock</a>from <a href="http://www.imdb.com/title/tt0060028/">“Star Trek”</a> (1966) - (Haskell) “…embracing logic and truth. His character has a single-minded purity that has endeared him to generations.”</li>
            </ul>
            
            <p>Even though I’ve only began working through the exercises in the Ruby section, I’ve already developed an intuition about the “personality” of each of these languages through Tate’s analogies.  He has also chosen the perfect level of detail, not spending any time on the details of the syntax, or building up canonical examples, only focusing on what makes each language unique and powerful and expecting the reader to explore on his or her own to fill in the gaps. I’ve almost worked through the Ruby section, so expect a post about that soon.  In the mean time, how do you feel about the Rule of Diversity?  Have you been offput when teachers/mentors/bosses treat a particular idea/framework/concept as “The One True Way”?</p>
          </article>
        </div>
        <div class='post'>
          <h1>
            <a href="/2012/08/what-makes-good-software-good/">What Makes Good Software Good?</a>
          </h1>
          <aside>Posted at: August 29, 2012</aside>
          <article>
            <p>The first day of class (ECE2524: Introduction to Unix for Engineers) I asked participents the  open ended question “What makes good software good?” and asked them to answer both “for the developer” and “for the consumer”. I generated a list of words and phrases for each sub-response and then normalized it based on my own intuition (e.g. I changed “simplicity” to “simple”, “easy to use” to “intuitive”, etc.). I then dumped the list into <a href="http://www.wordle.net/">Wordle</a> to generate these images: <strong>Good Software for the Consumer</strong><strong>Good Software for the Developer</strong> For a future in-class exercise I plan to ask participants to link the common themes that appear in these word clouds back to specific rules mentioned in <a href="http://catb.org/esr/writings/taoup/html/ch01s06.html">the reading</a>.</p>
          </article>
        </div>
        <div class='post'>
          <h1>
            <a href="/2012/05/it-may-be-satire/">It may be satire...</a>
          </h1>
          <aside>Posted at: May 1, 2012</aside>
          <article>
            <p>…but it also is perfectly relevant to the discussion we had in PFP about teaching evaluations: <a href="http://www.theonion.com/articles/professor-deeply-hurt-by-students-evaluation,20130/">http://www.theonion.com/articles/professor-deeply-hurt-by-students-evaluation,20130/</a> and the last “quote” is especially relevant to the discussion in GEDI about teaching responsibilities:</p>
            
            <blockquote>
              <p>“Students and the enormous revenue they bring in to our institution are a more valued commodity to us than faculty,” Dean James Hewitt said. “Although Rothberg is a distinguished, tenured professor with countless academic credentials and knowledge of 21 modern and ancient languages, there is absolutely no excuse for his boring Chad with his lectures. Chad must be entertained at all costs.”  
             Do you think there’s some truth to that?   </p>
            </blockquote>
          </article>
        </div>
        <div class='post'>
          <h1>
            <a href="/2012/05/a-matter-of-standards/">A Matter of Standards</a>
          </h1>
          <aside>Posted at: May 1, 2012</aside>
          <article>
            <p>Last night on my bike ride home from PFP class I mentally prepared a “todo list” of things to get done in the couple of hours I’d have  before getting too tired to be productive.  In a classic example of the story of my life, all that mental preparation went out the window when I finally arrived home, checked my email (probably mistake #1, checking email wasn’t on the original todo list) and read a message from a student in the class I’m teaching, ECE2524: Introduction to Unix for Engineers. On the face of it, the question seemed to be a simple one: “how do I display a certain character on the screen?” Furthermore, they noted that when they compiled their program in Windows, it worked fine and displayed the character they wanted, a block symbole: ▊, but when compiling and running on Linux the character displayed as a question mark ‘?’ Now, before you get turned off by words like “compile” and “Linux”, let me assure you, this all has a point and it relates to a discussion we had in PFP about “standards for the Ph.D.” plus, it resulted in one of my favorite methods of procrastination, exploring things we take for granted and discovering why we do things the way we do. After some googling around I came across this <a href="http://www.joelonsoftware.com/articles/Unicode.html">excellent post</a>, from which I pulled many of the examples that I use here. The problem was one of standards, but before we can talk about that we need to know a little bit about the history of how characters are stored and represented on a computer.  Even if you aren’t a computer engineer you probably know that computers don’t work with letters at all, they work with numbers, and you probably know they work with numbers represented in base 2, or binary, where ‘10’ represents ‘2’, ‘11’ represents 3, ‘100’ is a ‘4’ and so on.  And if you didn’t know some or any of that, that’s perfectly ok, because you don’t actually <strong>need **to know how a computer stores and manipulates information in order to use a computer any more, but back in the early days of computing, you did.  Also important for the story, back in the early days of computing the kind of information people needed to represent was much more limited, pictures and graphics of any kind were far beyond the capabilities of hardware used to represent information, in fact, early computer terminals were just <a href="http://en.wikipedia.org/wiki/Teleprinter">glorified typewriters</a>, only capable of representing letters in the <a href="http://en.wikipedia.org/wiki/Latin_alphabet">Classical Latin alphabet</a>, a-z, A-Z, numbers 0-9 and, because much of the early development was done in the United States, punctuation used in the English language.  To represent these letters with numbers a code had to be developed: a 1 to 1 relationship between a number and a letter.  The code that  came to widespred use, was called </strong>American Standard Code for Information Interchange, <strong>or</strong><a href="http://en.wikipedia.org/wiki/ASCII">ASCII</a>. ** [caption id=”” align=”alignnone” width=”723” caption=”ASCII chart”][/caption] This was a nice code for the time, with a total of 128 characters, any once character could be represented with 7 digital bits (2^7 = 128), so for instance 100 0001 in binary, which is 65 in good ol’ base 10, represents upper case ‘A’ while 110 001, or 97 represents lower case ‘a’.  For technical reasons it is convenient to store binary data in chunk bits totaling a <a href="http://en.wikipedia.org/wiki/Power_of_two#Computer_science">power of 2</a>.  7 is not a power of two, but 8 is, and so early computers stored and used information in chunks of 8 bits (today’s modern processors use data in chunks of 32 or 64 bits). Well, this was all fine and good, we could represent all the printed characters we needed, along with a set of “control” characters that were used for other purposes needed for transmitting data from one location to another.  But soon 128 characters started feeling limited, for one thing, even in English, it is sometimes useful to print accented characters, such as é in résumé.  Well, people noticed that ASCII only used 7 bits, but recognized that information was stored in groups of 8 bits, so there was a whole other bit that could be used.  People got creative and created <a href="http://en.wikipedia.org/wiki/Extended_ASCII">extended ASCII</a> which assigned symbols to the integer range 128-255 thereby making complete use of all 8 bits, but taking care not to change the meaning of the lower 127 codes, so for instance 130 now was used to represent é. The problem was that even 255 characters is not enough to represent the richness of <strong>all</strong> human languages around the world, and so as computer use became more prevalent in other parts of the world the upper 127 codes were used to represent different sets of symbols, for instance computers sold in Israel used 130 to represent the Hebrew letter Gimel (ג) instead of the accented é.  At first, everyone was happy.  People could represent all or most symbols needed for their native language (ignoring for the moment Chinese or Japanese, which have thousands of different symbols, with no hope of fitting in an 8-bit code). Then the unthinkable happened.  The Internet, and more to the point, email, changed the landscape of character representation, because all of a sudden people were trying to send and receive information to and from different parts of the world.  So now, when an American sent their résumé to their colleague in Isreal is showed up as a rגsumג.  Woops! But what to do?  At this point there were hundreds of different “code pages” used to represent a set of 255 characters with 8 bits.  While the lower 127 bits remained mostly consistent between code pages, the upper 127 were a bit of a free-for-all.  It became clear that a new standard was needed for representing characters on computers, one that could be used on any computer to represent any printed character of any human language, including ones that did could not easily be represented by only 255 characters. The solution is called Unicode, and it is a fundamentally different way of thinking about character representation.  In ASCII, and all the code pages developed after that, the relationship between a character and how that character was stored in computer memory was exact (even if different people didn’t agree what that relationship was).  In ASCII, an upper case ‘A’ was stored as 0100 0001, and if you could look at the individual bits physically stored in memory, that is what you would see, end of story.  Unicode relates letters to an abstract concept called a “code point”, a Unicode A is represented as U+0041.  A code point does **not **tell you anything about how a letter is stored in 1s and 0s, instead U+0041 just means the concept or idea of “upper case A”, likewise U+00E9 means the “lower case accented e”  (é), and U+05D2 means “the Hebrew letter gimel” (ג).  You can find all the Unicode representation for any supported character on the <a href="http://www.unicode.org/charts/">Unicode website</a>, or for quick reference at a variety of online charts, like <a href="http://www.tamasoft.co.jp/en/general-info/unicode.html">this one</a>. But remember, the Unicode representations are associated with the **concept **of the letter, not how it is stored on a computer.  The relationship between Unicode value and storage value is determined by the encoding scheme, the most common being <a href="http://en.wikipedia.org/wiki/UTF-8">UTF-8</a>.  A neat property of the UTF-8 encoding is that it is backwards compatible with the lower 127 ASCII characters, and so if those are the only characters you are using they’ll show up just fine in older software that doesn’t know anything about Unicode and assumes everything is in ASCII. I know I’m risking losing my point at this point, but one last thing.  Right click on this webpage and click “View Page Source”.  Near the top of the page you should see something that looks like  or  This is the line that tells your web browser what encoding scheme is used for the characters on this web page.  But “wait”, you might say, I have a self-reference problem, to write out “charset=UTF-8”, I need to first pick an encoding to use, so how can I tell the web browser what encoding I’m using without assuming it already knows what encoding I’m using?  Well, luckily, all the characters needed to write out the first few header lines, including “charset=UTF-8” just happen to be contained in the lower 127 characters of the original ASCII specification, which is the same as UTF-8 for that small range.  So web browsers can safely assume “UTF-8” until they read the line  at which point they will reload the page and switch to the specified encoding scheme. Ok. So where the heck was I going with this?  Well for one thing, the history of character representation is quite interesting and highlights various aspects of the history of computing, and sheds light on something that we all take for granted now, that I can open up a web page on any computer and be reasonably sure that the symbols used to represent the characters displayed are what the author intended. But it also highlights the importance of forming good standards, because without them, it is difficult to communicate across boundaries.  Standards don’t need to specify the details of implementation (how a character is stored in computer memory), but at the very least, to be useful and flexible they need to specify a common map between a specific concept (the letter ‘A’ in the Latin alphabet) and some agreed upon label (U+0041). Currently, we don’t really have a standardized way of talking about a Ph.D.  What is a “qualifier exam”? “prelims”?, “proposal”? all of these things could mean something different depending on your department and discipline.  While trying to standardize details such as “how many publications” or “how many years” or “what kind of work” would be difficult at best, nonsensical in many cases, to do across disciplines, we could start talking about standardizing the language we use to talk about various parts of the Ph.D process that are similar across fields. And incidentally, this is why I still haven’t finished grading the stack of homeworks I told myself I’d finish last night. And for what it’s worth, the answer to the student’s question was to use the Unicode representation of the ▊ symbol, which is standardized, not the extended-ASCII representation, which is **not **a standard way to represent that symbol.  </p>
          </article>
        </div>
        <div class='post'>
          <h1>
            <a href="/2012/04/industrialized-learning-knowledge-information/">Industrialized Learning: Knowledge != Information</a>
          </h1>
          <aside>Posted at: April 13, 2012</aside>
          <article>
            <p>To comment on Dan’s post titled <a href="https://blogs.lt.vt.edu/diggingdeeper/?p=42">Industrialized Learning??</a> I agree the the industrialization of the search for <strong>knowledge</strong> is a scary thing indeed, and in many respects the structure of our education system has suggested a trend in that direction (for more on that, <a href="http://www.youtube.com/watch?v=zDZFcDGpL4U">watch this excellent video</a>).  However, I don’t think that is necessarily Google’s goal.  As Carr mentioned, Google’s mission is “to organize the world’s information and make it universally accessible and useful.”  Organizing information, and creating tools to systematically archive and find information is <strong>not</strong> the same as industrializing the search for <strong>knowledge</strong>.  In fact, I would argue that the search for knowledge benefits if all the world’s existing information is organized in a systematic way to make it easy for anyone to access it.  Libraries have had a similar goal long before Google came around. Now certainly, the way our information is organized and the way we search for it does change the way we think about information, I think that was one of the key points in <a href="http://www.theatlantic.com/magazine/archive/2008/07/is-google-making-us-stupid/6868/">Carr’s article</a>.  However, changing the way we think in and of itself isn’t necessarily a bad thing, and it is in fact a continuous process that has been a reality since we were able to stand upright freeing our hands for tasks other than mobility. To be clear, I am not suggesting we give Google (or any other organization that deals with our information) _carte blanche_when it comes to the handling of the world’s information.  However, it is important to keep in mind that while information is a component of knowledge, information alone does not define knowledge.  The fear that the standardization and systematization of tasks will turn humans into mindless automatons is certainly something to think about and there is plenty of evidence from the Industrial Revolution that that is indeed the case.  However, the same economic forces that favor standardizing and systematization of a task also favor replacing a human automaton with a robot designed to complete that task.  Of course, currently we are facing a new problem as a result: how do we employ all these people who’s jobs have been replaced with robots?  We definitely need to have that discussion, but I don’t think the answer is to fight the systematization of tasks and put people back in those jobs, but rather to focus on what we are still better at than any  algorithm: creative thinking and imagination, and <strong>the search for knowledge</strong>.</p>
          </article>
        </div>
        <div class='post'>
          <h1>
            <a href="/2012/04/the-freedom-to-be-technologically-elite/">The Freedom to be "Technologically Elite"</a>
          </h1>
          <aside>Posted at: April 13, 2012</aside>
          <article>
            <p>Also in response to Kim’s <a href="https://blogs.lt.vt.edu/kimcowgill/2012/04/11/using-the-thing-im-complaining-about-to-do-the-thing-its-good-at-explaining-and-apologizing/">recent post</a>.  I think the conversation about access and the issue of digital inclusion is a very important one to have, and we need to continue to be aware of how the tools and technologies we use may include or exclude people.  I would like to talk a bit about the concept of the “technological elite” that Kim brought up.  It’s important to be aware that it is possible for an elite minority to control the tools the majority comes to depend and rely on, but that is not currently the case, and in fact, I would argue that it will only become a reality if the majority allows it to happen.  As Jon Udell mentioned in his conversation the Internet itself has always been and continues to be an inherently distributed technology.  No single organization, whether it be corporate or governmental, owns or controls it.  There have been attempts, and there will continue to be attempts to restrict freedoms and tighten control, like the recent attempted SOPA/PIPA legislation, but it is our responsibility to continue to be aware of those attempts and fight them. Many popular software tools in use, including <a href="http://en.wikipedia.org/wiki/WordPress">Wordpress</a> which powers this blog, are free and open source.  This means that anyone can take a look at the source code to learn what is going on behind the scenes, and in many cases, modify and improve that tool for your own or public use.  The language that Wordpress is written in, <a href="http://en.wikipedia.org/wiki/PHP">PHP</a> is not only open-source, but there are a plethora of free tutorials online for anyone interested in learning how to program in the language.  The database used by Wordpress to store and retrieve content, <a href="http://en.wikipedia.org/wiki/MySQL">MySQL</a> is currently open source, though the project itself was originally proprietary (Another relational database management system, <a href="http://en.wikipedia.org/wiki/PostgreSQL">PostgreSQL</a>, has been open source for the entirety of its live-time and in many cases can be used as a drop-in replacement for MySQL). The majority of servers powering the internet run some version of the <a href="http://en.wikipedia.org/wiki/Linux">Linux</a> operating system, itself freely available and open source. Each of these projects, at the various layers the build up to form the tools that we use are generally well documented with enough information freely available to allow anyone who wants to become an expert in their use and design.  Now of course, not everyone will become an expert, and they experts for any one project are not necessarily experts in any other.  But specialization has allowed us to advance as a society in a way that would not be possible without it. And because I love food: When many of us began specializing in fields that did not involve agriculture and food production, we became dependent on those who did for our very survival.  Yet I can’t remember the last time I’ve heard anyone call farmers members of the “Agricultural Elite”.  Like the Internet tools I’ve mentioned, any of us have the agency to become experts in farming if we so choose.</p>
          </article>
        </div>
        <div class='post'>
          <h1>
            <a href="/2012/03/strengthen-your-strength-know-your-weaknesses/">Strengthen your Strengths, know your Weaknesses</a>
          </h1>
          <aside>Posted at: March 24, 2012</aside>
          <article>
            <p>I spent most of today at a leadership workshop hosted by <a href="http://www.gradschools.org/">Alpha Epsilon Lambda</a>.  The theme of this year’s workshop was “emotional leadership” Some of the most important take-away points I think were:</p>
            
            <ul>
              <li>A leadership role does not equate a leadership position.  In fact there are many great leaders that do not lead from traditional leadership positions.  As Dean DePauw mentioned during her closing remarks, the ability to connect with people through social media, and there-by bypassing traditional channels that are generally controlled by those in leadership positions, has empowered people all over to become effective leaders, taking the Occupy movement and uprisings in Egypt and Syria as examples.</li>
              <li>There isn’t any one personality type that makes a leader.  In fact, anyone can be a leader, but it helps to be aware of ones own personality as that will affect leadership style.  Character, however, is critical to being a good leader.</li>
              <li>Everyone has their own strengths and weaknesses.  It is important to be aware of that.  Groups work most efficiently when everyone is utilizing their strengths.  While it is important to be aware of your weaknesses and work to bring them to some passible level, you will see much more gain when working on to improve your strengths.</li>
            </ul>
            
            <p>The last bullet point reminds me of a story from my undergrad past.  At the time, I was a competitive swimmer (now I’m just a swimmer who is a competitive person :) ), and I was a breaststroker.  Breaststroke is a weird stroke.  People either love it or hate it, and their feelings towards it generally align with their own performance in the stroke.  One could probably make the same argument for each other strokes as well, but I think most people would agree that breaststroke has the strongest distinction between “those that love it” and “those that hate it”.  In the Individual Medley (IM) event, the swimmer must swim equal distances of all for strokes: butterfly, backstroke, breaststroke and freestyle.  I often swam the IM at meets because, well, it was the only event other than breaststroke that I was reasonably competitive in.  In a large part, that was due to the love/hate relationship people have with breaststroke, and my couch understood that.  It might make sense to try and improve in ALL the strokes to become a good IMer, but of course that takes a lot of time and energy, and many times a lot of work only translates into a little bit of improvement in strokes that one is not naturally good at.  So my coach told me to focus on breaststroke, both in practice (of course, since that was my primary event anyway), but also when racing the IM.  You see, it wasn’t that important for me to beat anyoe in the fly, back or free.  That just wasn’t going to happen.  However, I could usually swim the other strokes to keep up with, or not fall to much behind my competitors.  And that’s all that was needed, because when the breaststroke came around I didn’t hold back.  I didn’t think about saving energy for the final leg of free, didn’t think about being tired from the previous two strokes, because if I was going to win the event, I had to put everything I had into that one segment. Most of the times, that strategy worked.  </p>
          </article>
        </div>
        <div class='post'>
          <h1>
            <a href="/2012/02/academic-privileged-experiences-as-a-white-cisgendered-gay-male-atheist-engineer/">Academic Privilege: Experiences as a white cisgendered gay male atheist Engineer</a>
          </h1>
          <aside>Posted at: February 29, 2012</aside>
          <article>
            <p>Wow.  So after skipping out of PFP early on Monday to attend a talk titled “Why are you Atheists so Angry” by Greta Christina, I was going to write a post about    what angers me about the current state of academia (for those of you not familiar with Greta’s talk, anger in this context is not a bad thing, it is a powerful motivator for social change).  In the process of confirming the url to her blog, a curious random happenstance led me to <a href="http://gretachristina.typepad.com/greta_christinas_weblog/2011/07/why-we-have-to-talk-about-this.html">this post</a> from July, 2011, which in turn lead to <a href="http://www.blaghag.com/2011/07/richard-dawkins-your-privilege-is.html">here </a>and finally to <a href="https://sindeloke.wordpress.com/2010/01/13/37/">Of Dogs and Lizards: A Parable of Privilege</a> I’m not going to rehash the situation and subsequent discussion that lead to the first two links, but if you have time for nothing else, read “Of Dogs and Lizards” immediately after this (or earlier if you find yourself thinking that I shouldn’t be “making a big deal” about this). This whole sequence of posts was really relevant to me because I had just spent a good deal of time last week discussing the concept of “privileged” with a group of friendly folks.  The parable did a better job of explaining it than I did, I think. It’s important to understand privilege because it exists at all levels in higher ed, and has a profound effect on the people that don’t have it.  Before I go on, there are many, many kinds of privileged and many of us have some but not all forms.  There’s white privilege, male privilege, straight privilege, <a href="http://en.wikipedia.org/wiki/Cisgender">cisgendered</a> privilege, religious (in this country, Christian) privilege and so on and so forth.  Notice I’m not talking about the privilege that comes with having a lot of money (although the previously mentioned kinds of privileged have a huge effect on whether or not someone achieves financial privilege).  I’m talking about _unearned_privileges.  Privileges granted just by being born a certain way, or adopting a certain religion. (Electrical) Engineering is a male dominated field, and while there have been many discussions as to why this is (and how to change it), one large reason is that it is not perceived as an inviting environment to women. As a gay male, I tend to be sensitive to sexist comments made by professors, colleagues, even my adviser.  Not for the same reason a woman would be sensitive to them, although I can empathize, but because they make me feel like an outlier, like I don’t belong.  I really don’t understand, why would we “hire some dancing girls” to celebrate a successful paper submission?  And why would I pick a major based on the ability “to meet women”? And why is talking about how engineers can “pick up girls” such a popular topic (here’s a tip, maybe if you started thinking of women as human beings (editors note: I originally had written “human beans”, which might be the case as well)  and not some kind of alien species that you had to “trick” into talking to you, you’d be more successful). I wish I could remember some more specific examples from the classroom.  All I can remember is numerous times feeling uncomfortable, both for myself, and for the few women around, after a professor (likely unknowingly) made a sexist comment in class. Now, if you have read the parable yet, you’ll understand that I am not accusing the people making these comments of being bad people. They’re just unaware.  They legitimately do not understand why the comments they are making might be offensive to some people.  Because they have privilege.  It’s not a bad thing, or a good thing, it’s just the state of the world that we live in.  But because they have privilege, they also have the privilege of ignoring the people who raise concerns. I have had good friends suggest that maybe I was just “an angsty gay boy” for feeling uncomfortable about the pervasive <a href="http://en.wikipedia.org/wiki/Heteronormativity">heteronormativity</a> I experience in Engineering.  I have been told by colleagues, after raising concern about a sexist remark made by a professor, that “it’s not a big deal, he didn’t mean it that way, don’t worry about it”.  Well, I am worried about it.  And I’m also worried when people tell me not to worry about it.  As you know by now from reading the referenced posts, these responses are a nice way of saying “shut up”.  Subconciously that is usually often done because maybe they see some truth in what I’m saying but don’t want to admit it because they’re uncomfortable facing the fact that they have privilege, or maybe it’s to try and preserve the privilege that they have. Academe should be an environment that is welcoming and inclusive to ALL people, and I think most of us feel that way.  So please, the next time someone tells you that a comment made them feel uncomfortable, listen to them.  And understand that it might take a while for you to understand WHY a comment that sounds perfectly reasonable to you might make someone else feel uncomfortable. What privileged to you enjoy that you might not be aware of? And how might they lead you to say things that may make others feel uncomfortable? What unearned privileges do you <em>not</em> have, and have you ever been made to feel uncomfortable, or unsafe as a result?  </p>
          </article>
        </div>
        <div class='post'>
          <h1>
            <a href="/2012/02/when-politics-attack/">When Politics Attack</a>
          </h1>
          <aside>Posted at: February 25, 2012</aside>
          <article>
            <p>It is generally understood that educators (and especially administrators) must maintain a reasonably level of objectivity and personal restraint when mentioning politics or other highly controversial topics.  We have a mission to reach out to ALL members of society, and alienating some showing strong endorsement for one side or another of a heated political debate is generally seen as antithetical to our mission. However, Brian Rosenberg, president of Macalester College, recently asked</p>
            
            <blockquote>
              <p>“Under what circumstances and to what extent should a college or university president speak directly to political issues and even speak publicly on particular political candidacies?”  
             Read his <a href="http://www.huffingtonpost.com/brian-rosenberg/santorum-2012_b_1300161.html?ref=fb&amp;src=sp&amp;comm_ref=false">full post</a> on Huffington Post. He concludes that when a political candidate, or the views of a candidate are a direct threat to the institution of education, then it is not only appropriate to speak up, but educators and administrators have a <em><strong>responsibility</strong></em><strong> to do so.</strong> I fully agree with his stance on this, and the particular examples he refers too, but I wonder where others fall? Are we all always going to agree which views are a direct threat to the institution, or will that opinion itself be clouded by personal bias and emotion?</p>
            </blockquote>
          </article>
        </div>
        <div class='post'>
          <h1>
            <a href="/2012/02/blogging-is-hard/">Blogging is hard</a>
          </h1>
          <aside>Posted at: February 12, 2012</aside>
          <article>
            <p>I started writing my first blog post for this course 10 days ago.  It is still in the draft folder.  This has been the common course of action throughout my blogging career.  I had attempted to start a blog a number of times long before signing up for either of these courses.  Previous attempts were all the same, initiated by outbursts of pent up desires to share my thoughts, dampened by the sudden realization that by sharing my thoughts others would be free to judge them.  How could I live with that? It’s not that I thought others would be harsh in their judgment, and in fact, it probably had less to do with how I felt others would look at my writing, but how I would judge it myself weeks or months later.  What was I thinking? Why hadn’t I bothered to look of the definition of that word, it clearly doesn’t fit there? I pick over the details of my work to such an extent that it doesn’t take long to convince myself anything I create isn’t ready for the world.  My blog just one example. But blogging shouldn’t be this hard.  There are no hard guidelines to meet, and so implicitly none that will be failed to be met.  Sure there will be reviews and critiques of a sort, but it’s easy enough to ignore that in a medium which lends itself perfectly to revision and constant adjustment.  Unlike a publication, there is little reason to obsess over small grammar issues and prudently check proper punctuation placement.  Even whimsical alliteration can scoot by under the radar without a second thought because the only gatekeeper to acceptance is myself. So what’s the big deal? Blogging is easy.</p>
          </article>
        </div>
      </div>
      <div id='footer'>
        a dkm production
      </div>
    </div>
  </body>
</html>
